{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project #1: Desperately Seeking Sutton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concepts explored in this project are covered by:\n",
    "- Lectures\n",
    "    - [Lesson 4: TD and Friends](https://classroom.udacity.com/courses/ud600/lessons/4178018883/concepts/43095686540923)\n",
    "- Readings\n",
    "    - [Learning to Predict by the Methods of Temporal Differences](http://incompleteideas.net/papers/sutton-88-with-erratum.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read Sutton's Paper\n",
    "#### 2. Write the code necessary to replicate Sutton's experiments\n",
    "    - You will be replicating figures 3, 4, and 5 (Check Erratum at the end of paper and [Ch. 7 Sutton Textbook](http://incompleteideas.net/book/ebook/node73.html)) \n",
    "#### 3. Create the graphs\n",
    "    - Replicate figures 3, 4, and 5\n",
    "#### 4. Write a paper describing the experiments, how you replicated them, and any other relevant information.\n",
    "    - Reminders:\n",
    "        - Include the hash for your last commit to the GitHub repository in the paperâ€™s header.\n",
    "        - 5 pages maximum\n",
    "        - use a conference paper format\n",
    "    - Contents:\n",
    "        - Describe the problem\n",
    "        - Your graphs \n",
    "        - Describe the experiments\n",
    "            - Discuss the implementation\n",
    "            - Discuss the outcome\n",
    "            - The generated data\n",
    "        - Describe your results\n",
    "            - How do they match\n",
    "            - How do they differ\n",
    "            - Why they do\n",
    "        - Describe any problems/pitfalls you encountered\n",
    "            - How did you overcome them\n",
    "            - What were your assumptions/justifications for this solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "You will be replicating figures 3, 4, and 5 (Check Erratum at the end of paper and [Ch. 7 Sutton Textbook](http://incompleteideas.net/book/ebook/node73.html)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Setup MDP and Helper function to generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\"\"\"Details of the Random Walk Problem from Sutton's 1988 Paper.  \n",
    "\n",
    "Starting state = {D}\n",
    "Non-Terminal States = {B, C, D, E, F}\n",
    "Terminal states = {A, G}\n",
    "\n",
    "Transition Probability for non-terminal states: 1/2\"\"\"\n",
    "\n",
    "#S - States\n",
    "S = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "\n",
    "#S_non_terminal - non terminal\n",
    "S_non_terminal = ['B', 'C', 'D', 'E', 'F']\n",
    "\n",
    "#S_terminal - terminal\n",
    "S_terminal=['A', 'G']\n",
    "\n",
    "R = {'A': 0, 'G': 1}\n",
    "\n",
    "#T - Transition Matrix\n",
    "transition_prob = 0.5\n",
    "\n",
    "T = np.zeros((len(S), len(S)))\n",
    "\n",
    "#1. fill out matrix\n",
    "T[S.index('B'), S.index('C')] = transition_prob\n",
    "T[S.index('B'), S.index('A')] = transition_prob\n",
    "T[S.index('C'), S.index('D')] = transition_prob\n",
    "T[S.index('C'), S.index('B')] = transition_prob\n",
    "T[S.index('D'), S.index('E')] = transition_prob\n",
    "T[S.index('D'), S.index('C')] = transition_prob\n",
    "T[S.index('E'), S.index('F')] = transition_prob\n",
    "T[S.index('E'), S.index('D')] = transition_prob\n",
    "T[S.index('F'), S.index('E')] = transition_prob\n",
    "T[S.index('F'), S.index('G')] = transition_prob\n",
    "\n",
    "def generate_episode(S, S_start, S_terminal, T):\n",
    "    \"\"\"Generate episodes of states, given transition matrix, T, states, S, and start (S_start) and terminal states (S_terminal).\n",
    "\n",
    "    Parameters: \n",
    "    S (list): all states\n",
    "    S_start (str): label of initial state\n",
    "    S_terminal (list): terminal states \n",
    "    T (numpy array): Transition Matrix\n",
    "\n",
    "    Returns:\n",
    "    list: single episode.\n",
    "\n",
    "   \"\"\"\n",
    "    episode = []\n",
    "\n",
    "    current_state = S_start\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        if len(episode) > 1000:\n",
    "            raise ValueError(\"Episode fails to terminate after {} timesteps.  Something's wrong with the code.\".format(len(episode)))\n",
    "        \n",
    "        episode.append(current_state)\n",
    "        \n",
    "        if current_state in S_terminal:                                                     #terminal states\n",
    "            return episode\n",
    "        else: \n",
    "            current_state = np.random.choice(S, replace=True, p=T[S.index(current_state)])  #non-terminal states\n",
    "\n",
    "def generate_dataset(S, S_start, S_terminal, T, n_episodes=10):\n",
    "    \"\"\"Generate datasets based on the Random Walk Problem from Sutton's 1988 Paper.  \n",
    "    \n",
    "    Starting state = {D}\n",
    "    Non-Terminal States = {B, C, D, E, F}\n",
    "    Terminal states = {A, G}\n",
    "    \n",
    "    Transition Probability for non-terminal states: 1/2\n",
    "\n",
    "    Parameters:\n",
    "    S (list): all states\n",
    "    S_start (str): label of initial state\n",
    "    S_terminal (list): terminal states \n",
    "    T (numpy array): Transition Matrix\n",
    "    n_episodes (int): # episodes to generate\n",
    "\n",
    "    Returns:\n",
    "    list of lists: dataset with episodes.\n",
    "\n",
    "   \"\"\"\n",
    "    \n",
    "    #2. generate n_episodes\n",
    "    return [generate_episode(S, S_start=S_start, S_terminal=S_terminal, T=T) for i in range(n_episodes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Figure 3] Experiment 1 - Widrow-Hoff Supervised Learning Procedure vs. TD Methods on Random Walk Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph to reproduce:\n",
    "\n",
    "<img src=\"img/Project1-Fig3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Given the **Random Walk Problem** as defined on the below MDP, calculate TD(Lambda), under lambdas 0, 0.1, 0.3, 0.5, 0.7, 0.9, and 1.  Plot RMS errors against these lambdas.\n",
    "\n",
    "<img src=\"img/Project1-MDP.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0. Setup\n",
    "#alpha - learning rate, fix alpha for figure 3\n",
    "fig3_alpha = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Generate 100 datasets - 10 episodes froms specified MDP (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'C', 'D', 'E', 'D', 'C', 'D', 'E', 'F', 'G']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Generate 100 training datasets of 10 episodes with given MP dynamics.                    \n",
    "n_episodes = 10\n",
    "n_datasets = 100\n",
    "\n",
    "##TO FREEZE DATASET, A PREVIOUS RUN WAS STORED AND WILL BE READ FROM FILE, datasets.csv.\n",
    "\n",
    "# datasets = [generate_dataset(S, S_start='D', S_terminal=['A', 'G'], T=T, n_episodes=n_episodes) for i in range(n_datasets)]\n",
    "# pd.DataFrame(datasets).to_csv(\"datasets.csv\",index=False)\n",
    "\n",
    "import ast\n",
    "\n",
    "datasets_saved = pd.read_csv('datasets.csv').to_numpy().tolist()\n",
    "datasets_saved = [[ast.literal_eval(l2) for l2 in l1] for l1 in datasets_saved]\n",
    "datasets = datasets_saved; datasets[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Start w/non-TD implementation of WH procedure to gain intuition => Confirm error ~ .25 (per figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++Experiment 1 Results: [WH Procedure] +++++++++++++\n",
      "Ideal:  [0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333334]\n",
      "Preds:  [0.10909918 0.07866158 0.01780591 0.78348722 0.89455869]\n",
      "RMSE:  2.5814787390626783\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Experiment 1 Comparison Fails w/ 'RMSE' of 2.5814787390626783",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-b6243d694493>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RMSE: '\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mP_pred_rmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m.15\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mP_pred_rmse\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m.28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Experiment 1 Comparison Fails w/ 'RMSE' of {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_pred_rmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: Experiment 1 Comparison Fails w/ 'RMSE' of 2.5814787390626783"
     ]
    }
   ],
   "source": [
    "# # - RMSE of 100 datasets (ideal - predictions).\n",
    "# verbose=True\n",
    "\n",
    "# def rmse(predictions, targets):\n",
    "#     return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "# #P_ideal - Ideal Predictions for non terminal states\n",
    "# P_ideal = [1/6, 1/3, 1/2, 2/3, 5/6]\n",
    "\n",
    "# #P_rmse = rmse(P_pred, P_ideal), where P_pred - Predictions for non terminal states\n",
    "# P_pred_rmse = np.mean(np.apply_along_axis(lambda P_pred: rmse(P_pred, P_ideal), 0, datasets_w))\n",
    "\n",
    "# P_pred_mean = np.mean(datasets_w, axis=1)\n",
    "\n",
    "# if verbose:\n",
    "#     print('++++++++++++++Experiment 1 Results: [WH Procedure] +++++++++++++')\n",
    "#     print('Ideal: ', P_ideal)\n",
    "#     print('Preds: ', P_pred_mean)\n",
    "#     print('RMSE: ',  P_pred_rmse)\n",
    "    \n",
    "# assert .15 <= P_pred_rmse <= .28, \"Experiment 1 WH Comparison Fails w/ 'RMSE' of {}\".format(P_pred_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Continue w/TD implementation of WH procedure [TD(1)] to confirm implementation => Confirm error ~.25 (per figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged at iter 51 w/w of [-3.22389737e-19  2.10521786e-01  5.14285714e-01  6.08694663e-01\n",
      "  7.39328132e-01]\n",
      "converged at iter 78 w/w of [0.09089883 0.22222218 0.53846154 0.78570817 0.98170042]\n",
      "converged at iter 38 w/w of [0.11974167 0.35598466 0.55172291 0.71998713 0.90954547]\n",
      "converged at iter 54 w/w of [0.42005804 0.53816967 0.57142688 0.76881381 0.98891993]\n",
      "converged at iter 58 w/w of [-1.46261785e-18  1.57893960e-01  3.66666666e-01  6.11104983e-01\n",
      "  8.44405943e-01]\n",
      "converged at iter 60 w/w of [0.19078604 0.61523997 0.76923076 0.93327899 0.98714782]\n",
      "converged at iter 58 w/w of [0.22657544 0.58298184 0.84615382 0.99999994 0.99997975]\n",
      "converged at iter 35 w/w of [0.08937002 0.08694726 0.27586035 0.59975661 0.76335276]\n",
      "converged at iter 30 w/w of [0.2646318  0.53124498 0.74358947 0.89281029 0.93248409]\n",
      "converged at iter 35 w/w of [-2.12152321e-19 -4.24304641e-19  3.04315426e-01  4.79979658e-01\n",
      "  7.63352757e-01]\n",
      "converged at iter 48 w/w of [0.32972866 0.43739852 0.53333331 0.63635943 0.87927643]\n",
      "converged at iter 46 w/w of [0.06662889 0.10810811 0.16666667 0.27774764 0.48920531]\n",
      "converged at iter 38 w/w of [2.10759252e-18 1.19997855e-01 2.42424183e-01 3.88682469e-01\n",
      " 6.28768674e-01]\n",
      "converged at iter 37 w/w of [0.23856886 0.30591268 0.28571278 0.42307079 0.68830353]\n",
      "converged at iter 52 w/w of [0.07140053 0.16666656 0.39393939 0.61904468 0.86354553]\n",
      "converged at iter 48 w/w of [0.24543169 0.58333222 0.63636363 0.68734053 0.87927643]\n",
      "converged at iter 45 w/w of [0.49563602 0.58333081 0.6666666  0.87465757 0.99127204]\n",
      "converged at iter 31 w/w of [0.11557389 0.24524771 0.49995583 0.53841397 0.63686522]\n",
      "converged at iter 47 w/w of [0.12251722 0.37489645 0.59259237 0.77770858 0.76853503]\n",
      "converged at iter 56 w/w of [0.48436385 0.6427191  0.73913011 0.9374461  0.99853499]\n",
      "converged at iter 52 w/w of [0.15373598 0.21739103 0.4137931  0.64701874 0.86354553]\n",
      "converged at iter 36 w/w of [0.07111538 0.23999237 0.42424219 0.54163893 0.65997884]\n",
      "converged at iter 65 w/w of [9.76549782e-20 1.05263039e-01 4.58333325e-01 7.49815314e-01\n",
      " 8.18400946e-01]\n",
      "converged at iter 73 w/w of [-5.69807510e-19  7.14273904e-02  2.27272724e-01  4.16629767e-01\n",
      "  7.81080347e-01]\n",
      "converged at iter 60 w/w of [-4.09194373e-19  3.84524982e-01  7.41935484e-01  9.49998544e-01\n",
      "  9.87147817e-01]\n",
      "converged at iter 49 w/w of [0.29828207 0.37931033 0.46666667 0.67999949 0.99015925]\n",
      "converged at iter 60 w/w of [0.0998203  0.17646813 0.42105127 0.88578911 0.98714782]\n",
      "converged at iter 36 w/w of [0.         0.38205845 0.62962207 0.79162613 0.91694028]\n",
      "converged at iter 41 w/w of [-1.43852316e-18  3.68355855e-01  6.45161131e-01  8.49909612e-01\n",
      "  9.01442034e-01]\n",
      "converged at iter 68 w/w of [-9.81757009e-19  3.99993653e-01  7.08333328e-01  9.99832189e-01\n",
      "  9.85116878e-01]\n",
      "converged at iter 68 w/w of [0.29976793 0.29999992 0.46428571 0.78568667 0.98511688]\n",
      "converged at iter 44 w/w of [0.32807679 0.47045879 0.63999796 0.76449554 0.89127204]\n",
      "converged at iter 40 w/w of [0.29556574 0.60867811 0.67647055 0.68178526 0.810447  ]\n",
      "converged at iter 60 w/w of [0.14102112 0.41647224 0.73683973 0.99908082 0.98714782]\n",
      "converged at iter 58 w/w of [0.         0.22128641 0.54999868 0.7855895  0.84440594]\n",
      "converged at iter 150 w/w of [0.21428571 0.31818182 0.27272727 0.33330228 0.95170398]\n",
      "converged at iter 85 w/w of [0.12499995 0.24       0.375      0.55537222 0.72665918]\n",
      "converged at iter 77 w/w of [0.30139573 0.79976025 0.76923077 0.79999997 0.99987323]\n",
      "converged at iter 38 w/w of [0.1963504  0.34615013 0.48780488 0.6666624  0.82685952]\n",
      "converged at iter 42 w/w of [0.36369892 0.40907889 0.475      0.6206893  0.76701326]\n",
      "converged at iter 49 w/w of [0.29828207 0.5999893  0.76923047 0.93300857 0.99015925]\n",
      "converged at iter 49 w/w of [0.18380106 0.46650429 0.67999949 0.9993828  0.99015925]\n",
      "converged at iter 92 w/w of [ 3.69154117e-19 -2.92167550e-18  7.40740741e-02  3.33330731e-01\n",
      "  9.76614135e-01]\n",
      "converged at iter 56 w/w of [0.48436385 0.83332091 0.775      0.76923073 0.99062183]\n",
      "converged at iter 42 w/w of [0.36369892 0.54995321 0.65624994 0.84615112 0.99933972]\n",
      "converged at iter 41 w/w of [0.13556756 0.46607075 0.7142847  0.80947241 0.90144203]\n",
      "converged at iter 56 w/w of [0.48436385 0.84209895 0.93023256 1.         0.99999956]\n",
      "converged at iter 45 w/w of [0.27128755 0.67999838 0.81081081 0.91303636 0.99127204]\n",
      "converged at iter 49 w/w of [0.13877802 0.61107455 0.78571421 0.93731733 0.99015925]\n",
      "converged at iter 50 w/w of [0.31822309 0.57112526 0.69999001 0.99983633 0.99946921]\n",
      "converged at iter 58 w/w of [0.09977815 0.29999928 0.4347825  0.69844703 0.84440594]\n",
      "converged at iter 54 w/w of [0.19932372 0.43478229 0.63333333 0.86653286 0.98891993]\n",
      "converged at iter 48 w/w of [0.21981911 0.4090882  0.54545454 0.68418283 0.87927643]\n",
      "converged at iter 46 w/w of [0.18110635 0.58170359 0.85714262 0.99999903 0.99943341]\n",
      "converged at iter 33 w/w of [ 1.51258586e-18 -7.17375383e-19  1.21211900e-01  1.81768206e-01\n",
      "  2.12333198e-01]\n",
      "converged at iter 113 w/w of [1.20047629e-19 5.88235294e-02 2.85714286e-01 4.99996624e-01\n",
      " 9.67995874e-01]\n",
      "converged at iter 78 w/w of [-8.17295334e-19  1.33332917e-01  4.99999905e-01  9.98502211e-01\n",
      "  9.81700416e-01]\n",
      "converged at iter 35 w/w of [0.08937002 0.09521322 0.25       0.45945942 0.76335276]\n",
      "converged at iter 52 w/w of [0.22057429 0.56243504 0.65384605 0.70583862 0.86354553]\n",
      "converged at iter 39 w/w of [0.24032468 0.49860553 0.45832303 0.52617383 0.71954757]\n",
      "converged at iter 42 w/w of [0.43598083 0.62499383 0.7027027  0.86955036 0.99251175]\n",
      "converged at iter 55 w/w of [0.1665193  0.22727246 0.26086942 0.49847837 0.70108996]\n",
      "converged at iter 56 w/w of [0.48436385 0.71413233 0.84375    0.91176471 0.94999645]\n",
      "converged at iter 78 w/w of [0.12481278 0.19999938 0.42857143 0.68749915 0.98170042]\n",
      "converged at iter 40 w/w of [0.07125725 0.14284566 0.3333322  0.57138265 0.810447  ]\n",
      "converged at iter 45 w/w of [0.18085837 0.58333081 0.64864865 0.56521298 0.65709976]\n",
      "converged at iter 50 w/w of [0.31822309 0.76189896 0.86842105 0.95651972 0.99484622]\n",
      "converged at iter 46 w/w of [0.18110635 0.63337381 0.90908102 0.99967126 0.99214483]\n",
      "converged at iter 51 w/w of [0.09067059 0.31818082 0.48484848 0.54999372 0.73932813]\n",
      "converged at iter 55 w/w of [0.22098039 0.57692304 0.62162162 0.58821446 0.70108996]\n",
      "converged at iter 113 w/w of [0.1111085  0.1875     0.27777778 0.74255764 0.96799587]\n",
      "converged at iter 43 w/w of [0.10918564 0.26086613 0.38888889 0.54544205 0.79137979]\n",
      "converged at iter 48 w/w of [0.15811628 0.44441202 0.57142849 0.73303313 0.87927643]\n",
      "converged at iter 52 w/w of [0.45348411 0.74074068 0.75       0.81817981 0.86354553]\n",
      "converged at iter 68 w/w of [-1.02087971e-18  5.88233445e-02  3.92857143e-01  7.05880135e-01\n",
      "  9.85116878e-01]\n",
      "converged at iter 47 w/w of [0.12251722 0.35288567 0.48275857 0.57891843 0.76853503]\n",
      "converged at iter 43 w/w of [0.09030322 0.24998299 0.37036988 0.35282421 0.54592819]\n",
      "converged at iter 43 w/w of [-7.02307606e-19  7.99996606e-02  3.12499980e-01  4.21003745e-01\n",
      "  5.45928192e-01]\n",
      "converged at iter 52 w/w of [0.11028714 0.3332621  0.57692299 0.7221984  0.86354553]\n",
      "converged at iter 54 w/w of [0.         0.12361499 0.52630977 0.85689399 0.98891993]\n",
      "converged at iter 58 w/w of [0.07689919 0.22222222 0.39393939 0.49997972 0.84440594]\n",
      "converged at iter 92 w/w of [-6.11371342e-19  9.52380952e-02  3.18181818e-01  7.13385588e-01\n",
      "  9.76614135e-01]\n",
      "converged at iter 52 w/w of [-1.19537986e-18  8.32252104e-02  4.81481444e-01  6.99993606e-01\n",
      "  8.63545528e-01]\n",
      "converged at iter 55 w/w of [0.09075945 0.31999996 0.56410256 0.72727188 0.70108996]\n",
      "converged at iter 41 w/w of [2.16126811e-18 1.65784322e-01 4.34772962e-01 6.49930880e-01\n",
      " 9.01442034e-01]\n",
      "converged at iter 65 w/w of [3.08093161e-19 1.90476148e-01 3.07692307e-01 4.16564063e-01\n",
      " 8.18400946e-01]\n",
      "converged at iter 51 w/w of [3.24551673e-18 1.30434571e-01 2.49999999e-01 3.88873245e-01\n",
      " 7.39328132e-01]\n",
      "converged at iter 43 w/w of [0.27310476 0.46623612 0.6333332  0.80769038 0.92715482]\n",
      "converged at iter 32 w/w of [0.19313263 0.35203294 0.40624823 0.39284646 0.53221311]\n",
      "converged at iter 56 w/w of [0.48436385 0.87999991 0.925      0.99999979 0.99958972]\n",
      "converged at iter 38 w/w of [0.32407673 0.62498152 0.70588225 0.76180665 0.82685952]\n",
      "converged at iter 68 w/w of [0.07691714 0.2962963  0.46875    0.71426061 0.98511688]\n",
      "converged at iter 49 w/w of [0.12289858 0.46103652 0.69998751 0.92799832 0.99015925]\n",
      "converged at iter 39 w/w of [1.46502810e-18 3.93430719e-01 8.14811007e-01 9.99962577e-01\n",
      " 9.93163651e-01]\n",
      "converged at iter 60 w/w of [0.12416019 0.23071499 0.40909077 0.64278163 0.98714782]\n",
      "converged at iter 60 w/w of [0.11072364 0.35293625 0.55555555 0.74997853 0.98714782]\n",
      "converged at iter 26 w/w of [0.         0.         0.33324016 0.45158374 0.58360529]\n",
      "converged at iter 22 w/w of [-2.83466030e-19  1.15231420e-01  2.05860294e-01  2.14130007e-01\n",
      "  2.89239677e-01]\n",
      "converged at iter 31 w/w of [0.11557389 0.28305121 0.45824078 0.6954415  0.79481108]\n",
      "converged at iter 48 w/w of [1.63800718e-18 1.99999799e-01 2.66666657e-01 2.85509237e-01\n",
      " 4.15412978e-01]\n"
     ]
    }
   ],
   "source": [
    "#2. Calculate TD Lambda (with various lambdas) with updates per dataset until convergence (store predicted weights for 100 datasets).\n",
    "verbose = False\n",
    "\n",
    "#alpha - learning rate, fix for all figure simulations\n",
    "alpha = fig3_alpha\n",
    "\n",
    "#lambd = lambda, eligibility trace\n",
    "lambd = 1\n",
    "\n",
    "#datasets_w - weights matrix, non terminal state weights per dataset    \n",
    "datasets_w = np.zeros((len(S_non_terminal), len(datasets)))\n",
    "\n",
    "for idx, dataset in enumerate(datasets):\n",
    "        \n",
    "    #w - weight vector (of predicted return) of s_non_terminal\n",
    "    w = np.zeros(len(S_non_terminal))\n",
    "\n",
    "    iter_counter = 0  \n",
    "    while True:                                                         # Iter over dataset - until convergence\n",
    "        \n",
    "        iter_counter += 1\n",
    "        \n",
    "        if iter_counter > 10000:\n",
    "            raise ValueError(\"Learner fails to converge after {} timesteps.  Something's wrong with the code.\".format(iter_counter))\n",
    "        \n",
    "        #w_delta - weight update term, sequence level\n",
    "        w_delta = np.zeros(len(S_non_terminal))\n",
    "    \n",
    "        for seq in dataset:\n",
    "            \n",
    "            #eligibility - eligibility trace\n",
    "            eligibility = np.zeros(len(S_non_terminal))\n",
    "\n",
    "            #z - return\n",
    "            z = R[seq[-1]]\n",
    "            \n",
    "            if verbose:\n",
    "                print('seq', seq)\n",
    "                print('z', z)\n",
    "\n",
    "            for t, S_t in enumerate(seq[:-1]):\n",
    "\n",
    "                #x_t - observation vector\n",
    "                x_t = (np.array(S_non_terminal) == S_t).astype(int)\n",
    "                \n",
    "                S_t_1 = seq[t+1]\n",
    "                \n",
    "#                 if t == len(seq[:-1])-1:\n",
    "#                     #x_t_1 - observation vector, x_(t + 1)\n",
    "#                     x_t_1 = np.zeros(len(S_non_terminal))\n",
    "#                 else:\n",
    "                x_t_1 = (np.array(S_non_terminal) == S_t_1).astype(int)\n",
    "                \n",
    "                eligibility *= lambd\n",
    "                eligibility += x_t\n",
    "                \n",
    "                if t == len(seq[:-1])-1:\n",
    "                    #td_error - td error, when S_t is last non-terminal state\n",
    "                    td_error = (z - np.dot(w, x_t))\n",
    "\n",
    "                else:\n",
    "                    #td_error - td error otherwise\n",
    "                    td_error = (np.dot(w, x_t_1 - x_t))                    \n",
    "                    \n",
    "                #w_delta_t - weight update term, sequence level per S_t\n",
    "                w_delta_t =  alpha * td_error * eligibility\n",
    "                \n",
    "                w_delta += w_delta_t\n",
    "                if verbose:\n",
    "#                     print('S_t', S_t)\n",
    "                    print('x_t', x_t)  \n",
    "                    print('TD Error', td_error)\n",
    "                    print('w_delta_t', w_delta_t)\n",
    "\n",
    "        w += w_delta \n",
    "\n",
    "        if np.max(np.abs(w_delta)) < 0.001: \n",
    "            print('converged at iter {0} w/w of {1}'.format(iter_counter,w))\n",
    "            datasets_w[:, idx] = w\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++++++++++++++Experiment 1 Results: [WH Procedure] +++++++++++++\n",
      "Ideal:  [0.16666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333334]\n",
      "Preds:  [0.15811075 0.35896154 0.52842157 0.69642402 0.8534188 ]\n",
      "RMSE:  0.1699005884863542\n"
     ]
    }
   ],
   "source": [
    "# - RMSE of 100 datasets (ideal - predictions).\n",
    "verbose=True\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "#P_ideal - Ideal Predictions for non terminal states\n",
    "P_ideal = [1/6, 1/3, 1/2, 2/3, 5/6]\n",
    "\n",
    "#P_rmse = rmse(P_pred, P_ideal), where P_pred - Predictions for non terminal states\n",
    "P_pred_rmse = np.mean(np.apply_along_axis(lambda P_pred: rmse(P_pred, P_ideal), 0, datasets_w))\n",
    "\n",
    "P_pred_mean = np.mean(datasets_w, axis=1)\n",
    "\n",
    "if verbose:\n",
    "    print('++++++++++++++Experiment 1 Results: [TD Implementation of WH Procedure] +++++++++++++')\n",
    "    print('Ideal: ', P_ideal)\n",
    "    print('Preds: ', P_pred_mean)\n",
    "    print('RMSE: ',  P_pred_rmse)\n",
    "    \n",
    "assert .15 <= P_pred_rmse <= .28, \"Experiment 1 TD-WH Comparison Fails w/ 'RMSE' of {}\".format(P_pred_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Continue w/TD implementation w/lambdas in [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1] => Confirm graph(per figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lambda= 0\n",
      "converged at iter 118 w/w of [0.20855516 0.38998042 0.56285288 0.68252613 0.91689232]\n",
      "converged at iter 115 w/w of [0.13588718 0.25934409 0.46579876 0.64959592 0.99725707]\n",
      "converged at iter 106 w/w of [0.08492768 0.2406529  0.46162181 0.60205744 0.76202285]\n",
      "converged at iter 114 w/w of [0.12927515 0.3226296  0.56439965 0.79290049 0.94456829]\n",
      "converged at iter 105 w/w of [0.04111469 0.14450456 0.26579019 0.41025446 0.65094558]\n",
      "converged at iter 112 w/w of [0.06646094 0.3680087  0.56799921 0.74616415 0.96066235]\n",
      "converged at iter 135 w/w of [0.27303647 0.59356389 0.76595852 0.87823204 0.93383671]\n",
      "converged at iter 115 w/w of [0.16678086 0.31596868 0.46009095 0.67225359 0.79321081]\n",
      "converged at iter 122 w/w of [0.31961659 0.44343893 0.55837891 0.69776391 0.80739016]\n",
      "converged at iter 99 w/w of [0.01057526 0.07169136 0.4699486  0.61579855 0.75769607]\n",
      "converged at iter 115 w/w of [0.1818251  0.34189856 0.56158968 0.69376621 0.89368096]\n",
      "converged at iter 108 w/w of [0.10062446 0.19437944 0.2616334  0.41818467 0.62590021]\n",
      "converged at iter 115 w/w of [0.14694214 0.34426634 0.46089771 0.67304129 0.81601197]\n",
      "converged at iter 101 w/w of [0.03704437 0.15864437 0.36497298 0.50377784 0.65001493]\n",
      "converged at iter 108 w/w of [0.12040434 0.21738427 0.36095028 0.5015958  0.74210833]\n",
      "converged at iter 120 w/w of [0.21234272 0.44218096 0.56313716 0.75649899 0.91498196]\n",
      "converged at iter 130 w/w of [0.36671505 0.53671656 0.66509729 0.83957116 0.9496841 ]\n",
      "converged at iter 109 w/w of [0.12243597 0.26069444 0.56021619 0.69871561 0.82353951]\n",
      "converged at iter 107 w/w of [0.04738897 0.20163531 0.36437483 0.54660305 0.7396471 ]\n",
      "converged at iter 126 w/w of [0.22172276 0.46936109 0.66709375 0.8550883  0.94510132]\n",
      "converged at iter 115 w/w of [0.17773135 0.29719662 0.46139398 0.64416104 0.86054742]\n",
      "converged at iter 107 w/w of [0.12494518 0.2253042  0.36011471 0.50916233 0.66616716]\n",
      "converged at iter 116 w/w of [0.14412167 0.27442769 0.46449873 0.69778826 0.9446987 ]\n",
      "converged at iter 114 w/w of [0.02264319 0.10795958 0.26976392 0.47135378 0.77277516]\n",
      "converged at iter 111 w/w of [0.06638223 0.36749489 0.56723161 0.69838557 0.95368357]\n",
      "converged at iter 114 w/w of [0.17333078 0.35861829 0.4609155  0.58237271 0.80826752]\n",
      "converged at iter 119 w/w of [0.12431492 0.2595885  0.46477164 0.83007843 0.94567681]\n",
      "converged at iter 106 w/w of [0.06443244 0.24222602 0.46257268 0.62009619 0.76061597]\n",
      "converged at iter 116 w/w of [0.16703768 0.41094939 0.56135626 0.72826396 0.87212981]\n",
      "converged at iter 113 w/w of [0.07413514 0.27793027 0.46666068 0.69839042 0.94433688]\n",
      "converged at iter 115 w/w of [0.14356617 0.29911929 0.46368643 0.66104906 0.93844944]\n",
      "converged at iter 130 w/w of [0.30278891 0.46843373 0.66671177 0.82812666 0.94634258]\n",
      "converged at iter 120 w/w of [0.24390011 0.41903435 0.56110697 0.70869082 0.8634103 ]\n",
      "converged at iter 114 w/w of [0.11866699 0.29742012 0.56668597 0.81831558 0.97131845]\n",
      "converged at iter 108 w/w of [0.         0.11929817 0.37115485 0.58471109 0.8119821 ]\n",
      "converged at iter 150 w/w of [0.03440653 0.08273781 0.17113429 0.41552792 0.95170398]\n",
      "converged at iter 125 w/w of [0.07934936 0.14492183 0.26745815 0.52186397 0.86386768]\n",
      "converged at iter 128 w/w of [0.16563917 0.57806479 0.76861334 0.87368767 0.96398901]\n",
      "converged at iter 112 w/w of [0.1655345  0.34293431 0.45947527 0.58668145 0.7533242 ]\n",
      "converged at iter 110 w/w of [0.11889324 0.33260166 0.46095633 0.5816279  0.73718951]\n",
      "converged at iter 121 w/w of [0.2266486  0.3903651  0.56363731 0.77343794 0.92086978]\n",
      "converged at iter 114 w/w of [0.07202482 0.39566258 0.56669651 0.79299152 0.92686636]\n",
      "converged at iter 115 w/w of [0.0275729  0.08660877 0.16968978 0.31716759 0.6344111 ]\n",
      "converged at iter 125 w/w of [0.24735617 0.52109077 0.66592061 0.7561856  0.96790054]\n",
      "converged at iter 128 w/w of [0.31294849 0.51763845 0.66218587 0.79483698 0.88187508]\n",
      "converged at iter 127 w/w of [0.25583134 0.4678939  0.66540437 0.79797117 0.92396711]\n",
      "converged at iter 124 w/w of [0.2497704  0.52509408 0.6596594  0.74274471 0.81840606]\n",
      "converged at iter 113 w/w of [0.17463193 0.33069918 0.45981675 0.60150041 0.7947449 ]\n",
      "converged at iter 117 w/w of [0.16338683 0.40246566 0.56339723 0.75641418 0.91480888]\n",
      "converged at iter 118 w/w of [0.11289415 0.36416232 0.5643315  0.87658085 0.92598546]\n",
      "converged at iter 121 w/w of [0.08508252 0.22159213 0.36497426 0.70496219 0.86429057]\n",
      "converged at iter 122 w/w of [0.24519552 0.42134621 0.56418256 0.75802004 0.93622771]\n",
      "converged at iter 120 w/w of [0.22556104 0.42051624 0.56281059 0.71980049 0.9026546 ]\n",
      "converged at iter 121 w/w of [0.16555686 0.44807474 0.66376803 0.7883554  0.88423194]\n",
      "converged at iter 92 w/w of [0.03914399 0.08780925 0.16587652 0.26453424 0.41732715]\n",
      "converged at iter 124 w/w of [0.0411657  0.09272319 0.26995588 0.47239592 0.9771074 ]\n",
      "converged at iter 120 w/w of [0.06088833 0.15962931 0.3685255  0.70882625 0.93210841]\n",
      "converged at iter 92 w/w of [0.05123359 0.14858636 0.26233886 0.33730409 0.4831726 ]\n",
      "converged at iter 111 w/w of [0.1094746  0.2589557  0.46305394 0.64483852 0.86043408]\n",
      "converged at iter 107 w/w of [0.04131811 0.17593343 0.3654638  0.56228163 0.71416909]\n",
      "converged at iter 119 w/w of [0.23279689 0.43365776 0.56062297 0.69993961 0.85929155]\n",
      "converged at iter 129 w/w of [0.06214155 0.15388633 0.26872026 0.60509798 0.7629875 ]\n",
      "converged at iter 141 w/w of [0.37875686 0.59221834 0.76437842 0.84591898 0.90572533]\n",
      "converged at iter 110 w/w of [0.0445746  0.19036827 0.36664417 0.52556207 0.89454818]\n",
      "converged at iter 107 w/w of [0.10273987 0.18576191 0.36179263 0.53175653 0.69493043]\n",
      "converged at iter 113 w/w of [0.17102417 0.32403288 0.46044576 0.59476354 0.81372381]\n",
      "converged at iter 125 w/w of [0.25861836 0.54365156 0.66407709 0.77683027 0.93028918]\n",
      "converged at iter 140 w/w of [0.31280906 0.55355132 0.77020763 0.89847997 0.97881285]\n",
      "converged at iter 113 w/w of [0.16193581 0.30737742 0.46101289 0.61132939 0.84800838]\n",
      "converged at iter 115 w/w of [0.14954925 0.35062112 0.46248937 0.63303871 0.88922532]\n",
      "converged at iter 151 w/w of [0.02894344 0.13531636 0.27709583 0.78735645 0.98994153]\n",
      "converged at iter 112 w/w of [0.14139213 0.33179537 0.46063405 0.61034552 0.79909255]\n",
      "converged at iter 116 w/w of [0.12893897 0.41389691 0.56437588 0.77299703 0.92029304]\n",
      "converged at iter 108 w/w of [0.11207237 0.25622893 0.36056065 0.49337305 0.73790895]\n",
      "converged at iter 109 w/w of [0.07163724 0.18818892 0.36460144 0.52362486 0.83113268]\n",
      "converged at iter 111 w/w of [0.10248107 0.28837475 0.46296617 0.63226595 0.83028635]\n",
      "converged at iter 113 w/w of [0.15015248 0.28553704 0.46083472 0.65711677 0.84143434]\n",
      "converged at iter 115 w/w of [0.18913325 0.3158035  0.46052137 0.63093412 0.82998729]\n",
      "converged at iter 109 w/w of [0.101239   0.24027934 0.46261075 0.63214397 0.85545856]\n",
      "converged at iter 106 w/w of [0.         0.16929137 0.46991485 0.69698957 0.87906543]\n",
      "converged at iter 123 w/w of [0.29022636 0.42848253 0.56381229 0.73238391 0.95930203]\n",
      "converged at iter 122 w/w of [0.10171602 0.21129829 0.36585705 0.7104546  0.99312788]\n",
      "converged at iter 106 w/w of [0.0585249  0.22136523 0.46456265 0.61331223 0.84809474]\n",
      "converged at iter 108 w/w of [0.10749778 0.24611037 0.36094649 0.48688235 0.77066866]\n",
      "converged at iter 106 w/w of [0.06792254 0.19374303 0.4633422  0.64349814 0.79936666]\n",
      "converged at iter 115 w/w of [0.09605301 0.21993512 0.36367341 0.60279864 0.85785344]\n",
      "converged at iter 109 w/w of [0.10208697 0.23377945 0.36112812 0.53161708 0.75691593]\n",
      "converged at iter 113 w/w of [0.14566207 0.36032066 0.56012776 0.69873841 0.82361777]\n",
      "converged at iter 108 w/w of [0.12325374 0.25730139 0.46061425 0.58738348 0.74071126]\n",
      "converged at iter 125 w/w of [0.26879787 0.56403778 0.66237088 0.7875686  0.89889117]\n",
      "converged at iter 120 w/w of [0.2331032  0.43408755 0.56107308 0.7282242  0.86004383]\n",
      "converged at iter 114 w/w of [0.12833336 0.24609391 0.36135475 0.56138071 0.84415031]\n",
      "converged at iter 111 w/w of [0.07762822 0.22041069 0.4640499  0.71722741 0.86782879]\n",
      "converged at iter 116 w/w of [0.0942335  0.42738448 0.66567403 0.7896886  0.90920377]\n",
      "converged at iter 110 w/w of [0.07759842 0.22072406 0.465205   0.67689092 0.90122931]\n",
      "converged at iter 112 w/w of [0.11612797 0.27443025 0.46329903 0.64558784 0.89257632]\n",
      "converged at iter 101 w/w of [0.05614201 0.16108002 0.46270356 0.59478022 0.70920883]\n",
      "converged at iter 101 w/w of [0.07369054 0.16573429 0.26281883 0.40746912 0.5066908 ]\n",
      "converged at iter 106 w/w of [0.04128238 0.17570368 0.36492814 0.56143887 0.67269446]\n",
      "converged at iter 107 w/w of [0.03206275 0.10082907 0.16789259 0.33163996 0.50889167]\n",
      "\n",
      "lambda= 0.1\n",
      "converged at iter 111 w/w of [0.20589158 0.38979597 0.56395956 0.68120709 0.91291307]\n",
      "converged at iter 108 w/w of [0.13066848 0.25703139 0.46595645 0.6474851  0.9960722 ]\n",
      "converged at iter 99 w/w of [0.08321343 0.23947429 0.45836773 0.59747728 0.76143398]\n",
      "converged at iter 108 w/w of [0.13259589 0.31855345 0.55956341 0.78857026 0.94280167]\n",
      "converged at iter 100 w/w of [0.0421414  0.14318627 0.2678057  0.41728397 0.65732707]\n",
      "converged at iter 106 w/w of [0.07208346 0.37704322 0.57567011 0.75455025 0.96476276]\n",
      "converged at iter 129 w/w of [0.28079221 0.59288587 0.76710216 0.88136657 0.93541442]\n",
      "converged at iter 107 w/w of [0.16240189 0.31254743 0.46011089 0.67048377 0.78909835]\n",
      "converged at iter 115 w/w of [0.32762635 0.45147163 0.56391574 0.6992228  0.80615133]\n",
      "converged at iter 93 w/w of [0.01781359 0.0787165  0.46770876 0.61326433 0.75787587]\n",
      "converged at iter 110 w/w of [0.19835753 0.35648283 0.56925599 0.69838339 0.89082989]\n",
      "converged at iter 102 w/w of [0.10146511 0.19704871 0.26574277 0.42071403 0.6227095 ]\n",
      "converged at iter 108 w/w of [0.15154928 0.35098655 0.4655532  0.66936436 0.80882526]\n",
      "converged at iter 94 w/w of [0.03833479 0.1608046  0.36130663 0.49545735 0.64365081]\n",
      "converged at iter 102 w/w of [0.12028311 0.21847189 0.36287976 0.50411373 0.74635406]\n",
      "converged at iter 113 w/w of [0.20900514 0.44093138 0.56292138 0.75605963 0.91660669]\n",
      "converged at iter 123 w/w of [0.37121594 0.5383131  0.6636959  0.8358825  0.94907956]\n",
      "converged at iter 103 w/w of [0.12798175 0.26439127 0.56724472 0.70622004 0.82546467]\n",
      "converged at iter 102 w/w of [0.05299436 0.21036037 0.37077549 0.54750682 0.73468527]\n",
      "converged at iter 119 w/w of [0.23456267 0.47482322 0.66659119 0.85167893 0.94218128]\n",
      "converged at iter 108 w/w of [0.17845715 0.29965369 0.46420856 0.64423578 0.85815234]\n",
      "converged at iter 101 w/w of [0.12217378 0.22788544 0.36672134 0.51350576 0.66681512]\n",
      "converged at iter 109 w/w of [0.14015524 0.27034368 0.4687731  0.7067704  0.94176813]\n",
      "converged at iter 109 w/w of [0.02458458 0.11412921 0.27744272 0.47634856 0.76694292]\n",
      "converged at iter 105 w/w of [0.07036142 0.37151438 0.57382515 0.70599271 0.95269457]\n",
      "converged at iter 107 w/w of [0.17558698 0.36454449 0.46572819 0.58423823 0.80753445]\n",
      "converged at iter 112 w/w of [0.13054045 0.259783   0.4596023  0.82611723 0.94790202]\n",
      "converged at iter 100 w/w of [0.05868192 0.24004252 0.46642139 0.62438894 0.76300639]\n",
      "converged at iter 109 w/w of [0.16088565 0.40979672 0.56453619 0.73246741 0.87437666]\n",
      "converged at iter 107 w/w of [0.0735772  0.27661236 0.47242055 0.71312324 0.95032332]\n",
      "converged at iter 109 w/w of [0.14692677 0.30251084 0.46870013 0.67005546 0.94424107]\n",
      "converged at iter 122 w/w of [0.29738992 0.46477009 0.66514511 0.82393467 0.9430261 ]\n",
      "converged at iter 112 w/w of [0.24250797 0.42407651 0.56937314 0.71601292 0.86538631]\n",
      "converged at iter 109 w/w of [0.13126703 0.31558984 0.57682367 0.82461207 0.97432001]\n",
      "converged at iter 102 w/w of [0.         0.12183495 0.37524702 0.58284938 0.80145198]\n",
      "converged at iter 150 w/w of [0.03589411 0.08398906 0.17527722 0.42611377 0.95170398]\n",
      "converged at iter 119 w/w of [0.08201179 0.15137692 0.27529332 0.52513232 0.85667205]\n",
      "converged at iter 121 w/w of [0.1736283  0.58736967 0.77024124 0.87184128 0.96405434]\n",
      "converged at iter 105 w/w of [0.16963659 0.346369   0.45989533 0.58461484 0.75247482]\n",
      "converged at iter 103 w/w of [0.12062453 0.33491159 0.46414891 0.58496431 0.73867161]\n",
      "converged at iter 114 w/w of [0.23347039 0.40122219 0.57235399 0.77916204 0.92328251]\n",
      "converged at iter 107 w/w of [0.07596672 0.39901783 0.57086387 0.80236999 0.93454684]\n",
      "converged at iter 114 w/w of [0.0277128  0.08524928 0.16888225 0.32260054 0.65399254]\n",
      "converged at iter 117 w/w of [0.24089564 0.52169158 0.66966764 0.76050726 0.97114617]\n",
      "converged at iter 121 w/w of [0.3181232  0.52459044 0.66743505 0.79998188 0.88702612]\n",
      "converged at iter 119 w/w of [0.24746023 0.46524101 0.66594895 0.7964347  0.92267905]\n",
      "converged at iter 117 w/w of [0.25882028 0.53160434 0.66269768 0.74369975 0.81821019]\n",
      "converged at iter 106 w/w of [0.17123663 0.33093415 0.46112719 0.6043814  0.80252835]\n",
      "converged at iter 110 w/w of [0.16238805 0.41209705 0.56960639 0.7559496  0.91645307]\n",
      "converged at iter 111 w/w of [0.11766166 0.38025901 0.57700987 0.88683427 0.93455508]\n",
      "converged at iter 115 w/w of [0.08505618 0.2218444  0.3689405  0.70801829 0.85896581]\n",
      "converged at iter 114 w/w of [0.23816571 0.4223904  0.5675057  0.76001859 0.94104584]\n",
      "converged at iter 113 w/w of [0.22630564 0.42093681 0.56531818 0.72505131 0.90668218]\n",
      "converged at iter 116 w/w of [0.17935099 0.46298833 0.67644867 0.80389916 0.89625552]\n",
      "converged at iter 87 w/w of [0.04062727 0.08915707 0.1677251  0.26530877 0.41508101]\n",
      "converged at iter 117 w/w of [0.0445245  0.09446256 0.26395209 0.45968638 0.97166698]\n",
      "converged at iter 115 w/w of [0.06472152 0.1650315  0.37611626 0.71460834 0.92544586]\n",
      "converged at iter 87 w/w of [0.05195174 0.149813   0.26421417 0.34127145 0.49057116]\n",
      "converged at iter 104 w/w of [0.11020756 0.25761691 0.4606932  0.6403668  0.85679876]\n",
      "converged at iter 102 w/w of [0.04516946 0.17442296 0.36895469 0.57522039 0.72553282]\n",
      "converged at iter 113 w/w of [0.24246769 0.44440576 0.56988404 0.70938513 0.86522275]\n",
      "converged at iter 124 w/w of [0.07246853 0.17125184 0.28284518 0.61669928 0.77162868]\n",
      "converged at iter 134 w/w of [0.37625344 0.59030236 0.76582118 0.84695421 0.90552281]\n",
      "converged at iter 105 w/w of [0.04592697 0.19380184 0.37145179 0.53316787 0.9026635 ]\n",
      "converged at iter 101 w/w of [0.10162249 0.18271324 0.36262079 0.53680356 0.69967041]\n",
      "converged at iter 106 w/w of [0.16920897 0.32618361 0.46426382 0.59459135 0.80721058]\n",
      "converged at iter 117 w/w of [0.26041343 0.55109402 0.67003877 0.77991679 0.93050641]\n",
      "converged at iter 133 w/w of [0.31118694 0.5601156  0.7750583  0.89880488 0.97825618]\n",
      "converged at iter 106 w/w of [0.15942298 0.30864453 0.46190245 0.60804798 0.8450905 ]\n",
      "converged at iter 109 w/w of [0.15748649 0.35826123 0.46682759 0.63163886 0.88340006]\n",
      "converged at iter 147 w/w of [0.03248316 0.14740329 0.28672247 0.78606289 0.98863826]\n",
      "converged at iter 107 w/w of [0.14746999 0.34202698 0.47223734 0.6247051  0.80893613]\n",
      "converged at iter 109 w/w of [0.13272962 0.41326146 0.56447707 0.77277104 0.91714329]\n",
      "converged at iter 103 w/w of [0.12181695 0.26770571 0.36760125 0.49579917 0.73679261]\n",
      "converged at iter 104 w/w of [0.07768615 0.19404356 0.36910055 0.52638358 0.82686789]\n",
      "converged at iter 104 w/w of [0.10432082 0.28864008 0.46312499 0.63041098 0.82610525]\n",
      "converged at iter 107 w/w of [0.15665555 0.29063889 0.45999123 0.65093331 0.83774687]\n",
      "converged at iter 107 w/w of [0.18627158 0.31035498 0.45601066 0.62460158 0.82299753]\n",
      "converged at iter 103 w/w of [0.1055185  0.24550545 0.46480304 0.63411277 0.85963427]\n",
      "converged at iter 101 w/w of [0.         0.17335707 0.47658913 0.70910523 0.89040708]\n",
      "converged at iter 116 w/w of [0.29273477 0.42753748 0.56206236 0.73022579 0.95653799]\n",
      "converged at iter 118 w/w of [0.1006838  0.21184152 0.3664056  0.70456531 0.99190894]\n",
      "converged at iter 101 w/w of [0.06250841 0.23033358 0.47308538 0.62101215 0.85048274]\n",
      "converged at iter 103 w/w of [0.10893083 0.24814328 0.36753832 0.49552784 0.7688334 ]\n",
      "converged at iter 100 w/w of [0.06977478 0.19855179 0.46669263 0.64422507 0.79898274]\n",
      "converged at iter 108 w/w of [0.0940801  0.21716504 0.35873138 0.59195345 0.85416203]\n",
      "converged at iter 103 w/w of [0.09974385 0.23108597 0.3601119  0.53121029 0.75803738]\n",
      "converged at iter 107 w/w of [0.14534578 0.36689376 0.57054133 0.70810941 0.82726715]\n",
      "converged at iter 102 w/w of [0.12652853 0.26384884 0.4678099  0.59058175 0.73712321]\n",
      "converged at iter 118 w/w of [0.26834825 0.56593972 0.66594364 0.79152568 0.90038186]\n",
      "converged at iter 113 w/w of [0.23722448 0.44256282 0.56852235 0.73238161 0.86146413]\n",
      "converged at iter 109 w/w of [0.13684436 0.25765774 0.37093093 0.56530577 0.83873726]\n",
      "converged at iter 105 w/w of [0.08110317 0.23164113 0.47209184 0.71826284 0.8662702 ]\n",
      "converged at iter 111 w/w of [0.09929454 0.42832435 0.66917498 0.79794617 0.9181392 ]\n",
      "converged at iter 103 w/w of [0.08095794 0.21916232 0.46066673 0.67180498 0.89997871]\n",
      "converged at iter 106 w/w of [0.113841   0.27679477 0.46701517 0.6471372  0.8930263 ]\n",
      "converged at iter 95 w/w of [0.0539242  0.15146221 0.46259527 0.59767561 0.71058426]\n",
      "converged at iter 93 w/w of [0.07007384 0.16411735 0.2613057  0.40041701 0.49909152]\n",
      "converged at iter 99 w/w of [0.04103442 0.17113745 0.360788   0.55681447 0.66918511]\n",
      "converged at iter 103 w/w of [0.03163597 0.10304965 0.17174612 0.33834505 0.51674856]\n",
      "\n",
      "lambda= 0.3\n",
      "converged at iter 95 w/w of [0.19821554 0.38902565 0.56844964 0.68058021 0.90165519]\n",
      "converged at iter 94 w/w of [0.11751553 0.2505605  0.46935934 0.64882287 0.99194587]\n",
      "converged at iter 85 w/w of [0.08087535 0.23911897 0.45237387 0.58938987 0.76307383]\n",
      "converged at iter 95 w/w of [0.14737862 0.31403798 0.55053357 0.78432782 0.94289094]\n",
      "converged at iter 89 w/w of [0.04365885 0.13965867 0.27092107 0.42985168 0.66831629]\n",
      "converged at iter 94 w/w of [0.08696051 0.39859113 0.59402252 0.77462668 0.97282992]\n",
      "converged at iter 117 w/w of [0.29274213 0.5864292  0.76801238 0.88759849 0.93799227]\n",
      "converged at iter 92 w/w of [0.15628935 0.30584433 0.46137602 0.67175475 0.78421903]\n",
      "converged at iter 99 w/w of [0.34232032 0.46591176 0.57355411 0.70255252 0.80569133]\n",
      "converged at iter 80 w/w of [0.03090643 0.08863862 0.45957759 0.60319502 0.75364857]\n",
      "converged at iter 97 w/w of [0.23362269 0.38420353 0.5776102  0.69931117 0.88235424]\n",
      "converged at iter 90 w/w of [0.10523583 0.20493298 0.27563129 0.42930431 0.623416  ]\n",
      "converged at iter 93 w/w of [0.16007483 0.36157381 0.46967255 0.65375259 0.79064289]\n",
      "converged at iter 80 w/w of [0.04129099 0.16626637 0.3547739  0.48099738 0.63447152]\n",
      "converged at iter 89 w/w of [0.11848366 0.22152425 0.37024513 0.5154667  0.76210194]\n",
      "converged at iter 97 w/w of [0.20029217 0.43552264 0.55930186 0.75305505 0.92114108]\n",
      "converged at iter 106 w/w of [0.38026626 0.53973819 0.65859397 0.8272817  0.94763838]\n",
      "converged at iter 90 w/w of [0.13928974 0.27203845 0.58154249 0.72102045 0.82873676]\n",
      "converged at iter 89 w/w of [0.06109138 0.22561964 0.38362796 0.55191832 0.72766521]\n",
      "converged at iter 104 w/w of [0.26650266 0.49001104 0.66704383 0.84705571 0.93863277]\n",
      "converged at iter 93 w/w of [0.18050647 0.3051478  0.47029502 0.64430748 0.85183041]\n",
      "converged at iter 87 w/w of [0.11329418 0.23092857 0.37940431 0.52165808 0.66772752]\n",
      "converged at iter 95 w/w of [0.12696713 0.25620263 0.47534824 0.72511172 0.93587833]\n",
      "converged at iter 98 w/w of [0.02650609 0.12506205 0.2904679  0.48412541 0.7592473 ]\n",
      "converged at iter 93 w/w of [0.07739305 0.38281164 0.5903973  0.72443808 0.95159108]\n",
      "converged at iter 92 w/w of [0.18181111 0.37757718 0.47602874 0.58944656 0.8085432 ]\n",
      "converged at iter 98 w/w of [0.14076765 0.26074818 0.45118032 0.81976963 0.95448261]\n",
      "converged at iter 86 w/w of [0.04597146 0.23666821 0.4740254  0.63357646 0.77021765]\n",
      "converged at iter 93 w/w of [0.14166971 0.40314067 0.56972429 0.73833447 0.8740333 ]\n",
      "converged at iter 95 w/w of [0.07391605 0.27889065 0.49022142 0.74976763 0.96198241]\n",
      "converged at iter 96 w/w of [0.15291181 0.30783066 0.47752223 0.6870884  0.95498986]\n",
      "converged at iter 106 w/w of [0.29062169 0.46365783 0.66681375 0.81985005 0.93882403]\n",
      "converged at iter 97 w/w of [0.24020998 0.43434929 0.58584061 0.73029255 0.86976567]\n",
      "converged at iter 97 w/w of [0.15680186 0.3529264  0.60114311 0.8438542  0.98044848]\n",
      "converged at iter 90 w/w of [0.         0.12411217 0.38354058 0.58063909 0.77977809]\n",
      "converged at iter 150 w/w of [0.03938746 0.08813078 0.18310844 0.44254584 0.95170398]\n",
      "converged at iter 107 w/w of [0.09199034 0.16829939 0.29228432 0.53133867 0.84018543]\n",
      "converged at iter 106 w/w of [0.19115157 0.61079386 0.77470811 0.86753268 0.96396694]\n",
      "converged at iter 91 w/w of [0.17652543 0.35507224 0.46212422 0.5814163  0.75362931]\n",
      "converged at iter 89 w/w of [0.12785694 0.33893254 0.46983483 0.59408543 0.74630059]\n",
      "converged at iter 100 w/w of [0.24846672 0.42267546 0.58844827 0.78756003 0.92498707]\n",
      "converged at iter 95 w/w of [0.08879989 0.41158594 0.58487452 0.8276071  0.95246037]\n",
      "converged at iter 111 w/w of [0.02731399 0.08011132 0.16336597 0.33065723 0.69813873]\n",
      "converged at iter 101 w/w of [0.23398384 0.52867197 0.67887598 0.76927455 0.97761467]\n",
      "converged at iter 105 w/w of [0.33454042 0.54186235 0.67786605 0.80996075 0.89762355]\n",
      "converged at iter 101 w/w of [0.22778415 0.45979769 0.67001557 0.79495738 0.9167816 ]\n",
      "converged at iter 103 w/w of [0.2778437  0.54996747 0.67509869 0.75244884 0.8229416 ]\n",
      "converged at iter 93 w/w of [0.16829685 0.33990054 0.47091966 0.61566834 0.82187418]\n",
      "converged at iter 95 w/w of [0.15834923 0.4339987  0.58720807 0.76352071 0.92527765]\n",
      "converged at iter 97 w/w of [0.13121305 0.41225028 0.60230603 0.90902324 0.95196455]\n",
      "converged at iter 103 w/w of [0.08499225 0.22666124 0.38009218 0.71801201 0.85589749]\n",
      "converged at iter 98 w/w of [0.22024484 0.41973474 0.57120141 0.76234637 0.95005287]\n",
      "converged at iter 97 w/w of [0.22870757 0.42107893 0.56795837 0.73194305 0.91260065]\n",
      "converged at iter 102 w/w of [0.19982864 0.48551517 0.6996829  0.83422943 0.91854701]\n",
      "converged at iter 78 w/w of [0.04186482 0.09032082 0.17152756 0.26546586 0.40663046]\n",
      "converged at iter 113 w/w of [0.05163872 0.10245596 0.26461041 0.45244253 0.96799587]\n",
      "converged at iter 106 w/w of [0.06715021 0.17112009 0.39339377 0.73249381 0.91254325]\n",
      "converged at iter 78 w/w of [0.05395392 0.15309605 0.27030529 0.35304243 0.50980642]\n",
      "converged at iter 90 w/w of [0.11773308 0.26571786 0.46236455 0.63584272 0.85284124]\n",
      "converged at iter 90 w/w of [0.05146642 0.17175962 0.37802255 0.60257964 0.74748093]\n",
      "converged at iter 98 w/w of [0.26414697 0.46552256 0.586715   0.72638213 0.87512727]\n",
      "converged at iter 112 w/w of [0.09533336 0.20862494 0.31082013 0.63386251 0.78586276]\n",
      "converged at iter 120 w/w of [0.3733766  0.58845838 0.76940252 0.84816307 0.90336497]\n",
      "converged at iter 95 w/w of [0.04959922 0.20138138 0.38684147 0.55895972 0.92055634]\n",
      "converged at iter 88 w/w of [0.09612173 0.17264207 0.36386838 0.55062961 0.71379178]\n",
      "converged at iter 92 w/w of [0.16849766 0.33414786 0.47369435 0.59434683 0.79356393]\n",
      "converged at iter 100 w/w of [0.25963354 0.56497646 0.68310593 0.78849516 0.93262548]\n",
      "converged at iter 118 w/w of [0.3020705  0.5693194  0.78653312 0.90305182 0.97739298]\n",
      "converged at iter 91 w/w of [0.14884596 0.30785011 0.46457874 0.60200787 0.8350885 ]\n",
      "converged at iter 94 w/w of [0.1730615  0.37736929 0.47767289 0.62707615 0.8688013 ]\n",
      "converged at iter 137 w/w of [0.04180791 0.16947706 0.30218746 0.78016747 0.98459266]\n",
      "converged at iter 94 w/w of [0.15429405 0.35779341 0.49339177 0.65307302 0.82827148]\n",
      "converged at iter 95 w/w of [0.13689921 0.41189212 0.5671024  0.7769593  0.91368582]\n",
      "converged at iter 91 w/w of [0.1390609  0.28756381 0.38066281 0.50125872 0.7331607 ]\n",
      "converged at iter 92 w/w of [0.08566144 0.20011096 0.37699269 0.53528698 0.82248045]\n",
      "converged at iter 90 w/w of [0.10933503 0.2916247  0.46474476 0.62815574 0.82026119]\n",
      "converged at iter 92 w/w of [0.16743284 0.29926972 0.45533099 0.63124253 0.82319145]\n",
      "converged at iter 92 w/w of [0.18129567 0.29978479 0.44827858 0.61264209 0.80646083]\n",
      "converged at iter 90 w/w of [0.1152601  0.25789704 0.4706788  0.63953231 0.86869633]\n",
      "converged at iter 89 w/w of [0.         0.17805474 0.48863036 0.73371153 0.91295061]\n",
      "converged at iter 101 w/w of [0.29643132 0.4222485  0.55496765 0.72335951 0.95106703]\n",
      "converged at iter 107 w/w of [0.09152803 0.20591386 0.36430262 0.69269058 0.98732284]\n",
      "converged at iter 89 w/w of [0.07422139 0.24905512 0.49060863 0.63933019 0.85779242]\n",
      "converged at iter 91 w/w of [0.11076893 0.25192512 0.38208408 0.51622065 0.76757571]\n",
      "converged at iter 86 w/w of [0.07122317 0.20537698 0.47116103 0.64331965 0.79685565]\n",
      "converged at iter 94 w/w of [0.08956609 0.21125217 0.3491987  0.5718901  0.84781012]\n",
      "converged at iter 89 w/w of [0.09451337 0.2252455  0.35550997 0.52553824 0.75808081]\n",
      "converged at iter 93 w/w of [0.14645568 0.37952945 0.58828177 0.72573364 0.83732175]\n",
      "converged at iter 88 w/w of [0.13186961 0.27468532 0.47888995 0.59370965 0.72882556]\n",
      "converged at iter 102 w/w of [0.27341265 0.57666586 0.67837408 0.80394333 0.90503841]\n",
      "converged at iter 97 w/w of [0.24338874 0.45792671 0.58129139 0.73844567 0.86450271]\n",
      "converged at iter 97 w/w of [0.15089881 0.27957374 0.39037655 0.57531559 0.83108469]\n",
      "converged at iter 93 w/w of [0.08739707 0.25386606 0.49037155 0.72688575 0.86917043]\n",
      "converged at iter 97 w/w of [0.10149988 0.42261025 0.67565206 0.81722041 0.93772351]\n",
      "converged at iter 91 w/w of [0.08959654 0.22036909 0.45631293 0.66838485 0.90328938]\n",
      "converged at iter 92 w/w of [0.10561039 0.27439976 0.46975793 0.64555496 0.88758296]\n",
      "converged at iter 81 w/w of [0.05031604 0.1304841  0.45993593 0.60163427 0.71175766]\n",
      "converged at iter 79 w/w of [0.06408321 0.16468018 0.26232336 0.39095354 0.48891138]\n",
      "converged at iter 84 w/w of [0.04221167 0.16186865 0.35282029 0.54950486 0.66325074]\n",
      "converged at iter 95 w/w of [0.03123315 0.11032889 0.18296993 0.35663024 0.53666721]\n",
      "\n",
      "lambda= 0.5\n",
      "converged at iter 78 w/w of [0.1853572  0.38630742 0.57645939 0.68285771 0.88392496]\n",
      "converged at iter 81 w/w of [0.10226671 0.24292187 0.48024629 0.6633399  0.98431039]\n",
      "converged at iter 69 w/w of [0.08241325 0.24560688 0.44864798 0.5837037  0.76885053]\n",
      "converged at iter 82 w/w of [0.17857001 0.32075923 0.54425632 0.78576698 0.94869284]\n",
      "converged at iter 80 w/w of [0.04353136 0.13751166 0.27631319 0.44284652 0.67817238]\n",
      "converged at iter 81 w/w of [0.10846502 0.43112821 0.61941657 0.79935097 0.97942815]\n",
      "converged at iter 103 w/w of [0.29665534 0.57427027 0.76808483 0.89512998 0.94138051]\n",
      "converged at iter 75 w/w of [0.14932741 0.29240139 0.45736745 0.67403463 0.78104275]\n",
      "converged at iter 80 w/w of [0.35200916 0.47655906 0.58167746 0.7070979  0.80776826]\n",
      "converged at iter 65 w/w of [0.03814673 0.08725042 0.44461688 0.5861543  0.74454882]\n",
      "converged at iter 82 w/w of [0.2717979  0.41165975 0.5767052  0.68634824 0.86713927]\n",
      "converged at iter 79 w/w of [0.11159301 0.21534484 0.28606211 0.43890365 0.63132259]\n",
      "converged at iter 75 w/w of [0.16380182 0.36015746 0.45828495 0.61777871 0.76143729]\n",
      "converged at iter 66 w/w of [0.0488654  0.17631748 0.34824111 0.46758136 0.62918177]\n",
      "converged at iter 74 w/w of [0.1131513  0.2216786  0.37997372 0.53501513 0.78608276]\n",
      "converged at iter 79 w/w of [0.18997688 0.43182909 0.55521968 0.74617081 0.92551031]\n",
      "converged at iter 88 w/w of [0.39205584 0.54121222 0.65303209 0.82012853 0.94752585]\n",
      "converged at iter 77 w/w of [0.15177418 0.28155805 0.5980876  0.73587163 0.82967494]\n",
      "converged at iter 75 w/w of [0.06722907 0.24276543 0.40268126 0.56578923 0.72609825]\n",
      "converged at iter 88 w/w of [0.30751467 0.51347953 0.67166629 0.84748536 0.93923495]\n",
      "converged at iter 77 w/w of [0.18030542 0.30637207 0.47376838 0.64388048 0.84476267]\n",
      "converged at iter 71 w/w of [0.09767139 0.22729967 0.38789241 0.52487001 0.66428406]\n",
      "converged at iter 81 w/w of [0.10636103 0.23272777 0.47781187 0.74053922 0.92483666]\n",
      "converged at iter 91 w/w of [0.02563451 0.13480041 0.3018455  0.49143582 0.76226936]\n",
      "converged at iter 80 w/w of [0.08265521 0.39631091 0.61232905 0.74999528 0.95121734]\n",
      "converged at iter 76 w/w of [0.19344722 0.39230482 0.48605619 0.5958192  0.81329248]\n",
      "converged at iter 84 w/w of [0.14817689 0.26194473 0.44539008 0.81662039 0.96307357]\n",
      "converged at iter 71 w/w of [0.0330659  0.23945377 0.48512425 0.64795871 0.78613629]\n",
      "converged at iter 75 w/w of [0.11296744 0.39014896 0.57391464 0.74181759 0.8668807 ]\n",
      "converged at iter 84 w/w of [0.07416446 0.28914691 0.51876472 0.79690156 0.97196803]\n",
      "converged at iter 82 w/w of [0.16276106 0.31512568 0.48677808 0.70447674 0.96329811]\n",
      "converged at iter 88 w/w of [0.28396255 0.46696357 0.67318402 0.82076336 0.93830377]\n",
      "converged at iter 80 w/w of [0.23597856 0.44162167 0.59642737 0.73656481 0.87125915]\n",
      "converged at iter 84 w/w of [0.18108231 0.38985397 0.63112561 0.87188234 0.98557549]\n",
      "converged at iter 77 w/w of [0.         0.12709549 0.39627709 0.5855593  0.75968444]\n",
      "converged at iter 150 w/w of [0.04627989 0.09758505 0.19104479 0.450146   0.95170398]\n",
      "converged at iter 98 w/w of [0.10881784 0.19046861 0.31059517 0.53756661 0.8229581 ]\n",
      "converged at iter 97 w/w of [0.21746378 0.64469492 0.78052    0.86129088 0.96581326]\n",
      "converged at iter 74 w/w of [0.1791589  0.36538734 0.46642132 0.578726   0.75497822]\n",
      "converged at iter 73 w/w of [0.14154133 0.34242598 0.47516381 0.60695641 0.75800992]\n",
      "converged at iter 85 w/w of [0.26639305 0.44567506 0.60389327 0.79206805 0.921841  ]\n",
      "converged at iter 81 w/w of [0.1071924  0.42798921 0.60256067 0.85737558 0.96951125]\n",
      "converged at iter 107 w/w of [0.02512661 0.07061386 0.15196198 0.33654027 0.75493385]\n",
      "converged at iter 89 w/w of [0.24397791 0.55080672 0.69452126 0.78106766 0.98417736]\n",
      "converged at iter 89 w/w of [0.36268522 0.56506494 0.68863093 0.82134607 0.91165452]\n",
      "converged at iter 82 w/w of [0.20539958 0.456549   0.68042549 0.79700988 0.90614564]\n",
      "converged at iter 90 w/w of [0.30273858 0.58091022 0.70018514 0.7741984  0.83725596]\n",
      "converged at iter 78 w/w of [0.16929139 0.36143342 0.49205274 0.63648163 0.8471735 ]\n",
      "converged at iter 79 w/w of [0.15310283 0.46371536 0.61503225 0.78336846 0.94032044]\n",
      "converged at iter 82 w/w of [0.15072351 0.44462035 0.6281185  0.93414456 0.96961264]\n",
      "converged at iter 88 w/w of [0.08739363 0.24075113 0.39620764 0.72810506 0.85838698]\n",
      "converged at iter 80 w/w of [0.1942753  0.40849788 0.56909263 0.76094251 0.95802983]\n",
      "converged at iter 80 w/w of [0.23740326 0.42732985 0.57131195 0.73412557 0.91423805]\n",
      "converged at iter 87 w/w of [0.21048907 0.50268107 0.72435607 0.86572816 0.93904554]\n",
      "converged at iter 67 w/w of [0.0399702  0.08714499 0.17316621 0.26116956 0.38809237]\n",
      "converged at iter 113 w/w of [0.05429642 0.10893934 0.27166792 0.45672769 0.96799587]\n",
      "converged at iter 95 w/w of [0.06002311 0.16726544 0.41016997 0.75867506 0.90233937]\n",
      "converged at iter 68 w/w of [0.05592076 0.1562056  0.27735538 0.36922475 0.53806984]\n",
      "converged at iter 76 w/w of [0.13322597 0.29119936 0.47357003 0.63638068 0.85429046]\n",
      "converged at iter 76 w/w of [0.05764139 0.17398446 0.3911967  0.62977073 0.76649982]\n",
      "converged at iter 81 w/w of [0.29151341 0.48772815 0.60210368 0.74204216 0.88438539]\n",
      "converged at iter 97 w/w of [0.12044108 0.2470792  0.3351005  0.63673338 0.79164227]\n",
      "converged at iter 104 w/w of [0.37169509 0.58790259 0.7716828  0.84632902 0.89840811]\n",
      "converged at iter 85 w/w of [0.05536296 0.21078578 0.40953889 0.59720895 0.93784597]\n",
      "converged at iter 73 w/w of [0.08692713 0.15732996 0.36238713 0.56786858 0.7353891 ]\n",
      "converged at iter 76 w/w of [0.1714618  0.34737709 0.48393877 0.59097989 0.77735602]\n",
      "converged at iter 84 w/w of [0.25867942 0.58475345 0.70217079 0.80285026 0.93833301]\n",
      "converged at iter 101 w/w of [0.2813018  0.57486464 0.80316234 0.91466353 0.97824929]\n",
      "converged at iter 75 w/w of [0.13592952 0.30851864 0.47175716 0.59847485 0.81904477]\n",
      "converged at iter 78 w/w of [0.19084126 0.40526087 0.49464401 0.62224922 0.84983368]\n",
      "converged at iter 125 w/w of [0.05458085 0.18802347 0.31180187 0.76999472 0.97779418]\n",
      "converged at iter 79 w/w of [0.15743567 0.36951141 0.51403732 0.68395853 0.84838782]\n",
      "converged at iter 78 w/w of [0.13313266 0.40702135 0.56901611 0.78229341 0.9113842 ]\n",
      "converged at iter 78 w/w of [0.15722879 0.31053129 0.39932707 0.51502966 0.73316694]\n",
      "converged at iter 81 w/w of [0.08832326 0.19842658 0.38494717 0.55265529 0.82924304]\n",
      "converged at iter 75 w/w of [0.11692191 0.29459865 0.46461317 0.62465588 0.81481784]\n",
      "converged at iter 77 w/w of [0.17716702 0.310198   0.451751   0.60658574 0.80264771]\n",
      "converged at iter 76 w/w of [0.17574421 0.28741132 0.43963233 0.59745338 0.7816051 ]\n",
      "converged at iter 75 w/w of [0.1241837  0.2752475  0.48154769 0.64779117 0.87708759]\n",
      "converged at iter 76 w/w of [0.         0.17567932 0.49968948 0.76118763 0.93564187]\n",
      "converged at iter 84 w/w of [0.29862703 0.4138287  0.54350931 0.7110802  0.94306018]\n",
      "converged at iter 95 w/w of [0.07426851 0.19132016 0.35991723 0.68611579 0.97930968]\n",
      "converged at iter 77 w/w of [0.09369503 0.2689513  0.51016722 0.66383413 0.86861396]\n",
      "converged at iter 78 w/w of [0.11376746 0.25862114 0.40280944 0.54714312 0.77162401]\n",
      "converged at iter 71 w/w of [0.06700064 0.20678165 0.47162073 0.63862019 0.79468639]\n",
      "converged at iter 80 w/w of [0.08464449 0.20790464 0.34234699 0.55339647 0.84140174]\n",
      "converged at iter 74 w/w of [0.08816273 0.2211934  0.34986784 0.5146909  0.7566022 ]\n",
      "converged at iter 78 w/w of [0.15378111 0.39346033 0.60230215 0.74153656 0.85032147]\n",
      "converged at iter 72 w/w of [0.13546125 0.28165007 0.48381311 0.58927039 0.71578514]\n",
      "converged at iter 90 w/w of [0.29785221 0.61105839 0.70956522 0.83094195 0.91676298]\n",
      "converged at iter 79 w/w of [0.24978727 0.47549545 0.59462092 0.74410454 0.86882996]\n",
      "converged at iter 84 w/w of [0.16066794 0.29962148 0.41048609 0.58988925 0.8307448 ]\n",
      "converged at iter 80 w/w of [0.09207647 0.27590885 0.50966285 0.7407529  0.87895064]\n",
      "converged at iter 82 w/w of [0.09194993 0.40970162 0.68656847 0.84375356 0.9593834 ]\n",
      "converged at iter 78 w/w of [0.09894539 0.22170476 0.45257969 0.6702697  0.9134893 ]\n",
      "converged at iter 78 w/w of [0.09839568 0.26975049 0.46891683 0.6367088  0.87221275]\n",
      "converged at iter 66 w/w of [0.04794312 0.10661915 0.4517004  0.60010033 0.70920588]\n",
      "converged at iter 64 w/w of [0.05829547 0.16929294 0.26733649 0.38412001 0.48088245]\n",
      "converged at iter 70 w/w of [0.04639295 0.15496981 0.34812501 0.54851417 0.66257137]\n",
      "converged at iter 86 w/w of [0.03257309 0.12576879 0.20221963 0.38006098 0.5582008 ]\n",
      "\n",
      "lambda= 0.7\n",
      "converged at iter 60 w/w of [0.15166561 0.36638711 0.58179873 0.68373765 0.8536587 ]\n",
      "converged at iter 78 w/w of [0.09055879 0.23839998 0.50482881 0.70230546 0.98170042]\n",
      "converged at iter 54 w/w of [0.09288781 0.27270925 0.46048541 0.59376152 0.78796111]\n",
      "converged at iter 66 w/w of [0.23333577 0.348902   0.54090573 0.78793433 0.95860618]\n",
      "converged at iter 70 w/w of [0.03762959 0.13849961 0.28280381 0.45032312 0.68426078]\n",
      "converged at iter 66 w/w of [0.13624403 0.48261049 0.65799986 0.83229063 0.98133583]\n",
      "converged at iter 86 w/w of [0.28894919 0.56543748 0.77581628 0.91225663 0.95157617]\n",
      "converged at iter 57 w/w of [0.13700013 0.26503278 0.44159893 0.67343949 0.77972324]\n",
      "converged at iter 60 w/w of [0.3511595  0.48499753 0.59524678 0.72131842 0.81933221]\n",
      "converged at iter 51 w/w of [0.03440746 0.06872372 0.41965238 0.56191305 0.73616453]\n",
      "converged at iter 64 w/w of [0.30516486 0.43400941 0.56121999 0.65036289 0.8381703 ]\n",
      "converged at iter 67 w/w of [0.11450935 0.21884591 0.28600093 0.43162837 0.63059348]\n",
      "converged at iter 56 w/w of [0.15283768 0.32839383 0.41619551 0.55003939 0.71488032]\n",
      "converged at iter 52 w/w of [0.0742238  0.20062938 0.3396944  0.45173699 0.62651524]\n",
      "converged at iter 64 w/w of [0.10398341 0.21534453 0.39231339 0.56666752 0.8211685 ]\n",
      "converged at iter 60 w/w of [0.18302713 0.44327307 0.55924798 0.73299881 0.9239186 ]\n",
      "converged at iter 68 w/w of [0.40811601 0.54380072 0.64840896 0.8193662  0.95234811]\n",
      "converged at iter 60 w/w of [0.15628303 0.28373104 0.61019209 0.7397325  0.81593275]\n",
      "converged at iter 62 w/w of [0.07547025 0.27151228 0.43843235 0.59833376 0.73080631]\n",
      "converged at iter 74 w/w of [0.35817561 0.54775688 0.68430799 0.85861468 0.94742898]\n",
      "converged at iter 64 w/w of [0.175725   0.29744734 0.47123015 0.6461431  0.84478945]\n",
      "converged at iter 55 w/w of [0.07583583 0.21597009 0.39024911 0.52129917 0.65579054]\n",
      "converged at iter 71 w/w of [0.07531325 0.19546489 0.47450278 0.75028956 0.90162235]\n",
      "converged at iter 83 w/w of [0.01950433 0.13451691 0.29954154 0.48489867 0.77066008]\n",
      "converged at iter 65 w/w of [0.08075797 0.40871018 0.64555086 0.79378343 0.95215354]\n",
      "converged at iter 61 w/w of [0.21618955 0.40584463 0.49174637 0.60333007 0.82637425]\n",
      "converged at iter 71 w/w of [0.14881771 0.25690048 0.44132853 0.82183387 0.97237376]\n",
      "converged at iter 55 w/w of [0.02064782 0.25828666 0.50759791 0.67647492 0.8202709 ]\n",
      "converged at iter 56 w/w of [0.07501537 0.37339425 0.58288393 0.75213959 0.85730451]\n",
      "converged at iter 72 w/w of [0.06668084 0.30848577 0.56175874 0.85585461 0.97667092]\n",
      "converged at iter 71 w/w of [0.18916281 0.32983711 0.49930164 0.72890521 0.96970252]\n",
      "converged at iter 70 w/w of [0.27884229 0.47281531 0.6824371  0.82597942 0.94136704]\n",
      "converged at iter 61 w/w of [0.22889252 0.446906   0.59525392 0.72216977 0.86495219]\n",
      "converged at iter 67 w/w of [0.19073981 0.41563694 0.66357404 0.90568959 0.98505251]\n",
      "converged at iter 69 w/w of [0.         0.14128224 0.4272587  0.61705521 0.75651001]\n",
      "converged at iter 150 w/w of [0.06666022 0.12390822 0.20274054 0.44327126 0.95170398]\n",
      "converged at iter 93 w/w of [0.1298654  0.2159048  0.32868548 0.5423125  0.80630388]\n",
      "converged at iter 87 w/w of [0.24550621 0.68121562 0.77637022 0.84356663 0.97045963]\n",
      "converged at iter 55 w/w of [0.17365766 0.37428251 0.47671999 0.58584306 0.76029462]\n",
      "converged at iter 55 w/w of [0.17229617 0.35294167 0.48661242 0.63086836 0.77534522]\n",
      "converged at iter 68 w/w of [0.28430504 0.47503971 0.62460684 0.79504415 0.91380427]\n",
      "converged at iter 65 w/w of [0.13133373 0.4490296  0.62606792 0.8930838  0.98226671]\n",
      "converged at iter 102 w/w of [0.01906472 0.05342981 0.13192566 0.3398888  0.83061277]\n",
      "converged at iter 77 w/w of [0.28344368 0.59630524 0.71502396 0.79129243 0.98955999]\n",
      "converged at iter 73 w/w of [0.39705909 0.5851637  0.69146698 0.83165993 0.9330292 ]\n",
      "converged at iter 61 w/w of [0.17811593 0.45458618 0.69585544 0.80092123 0.88988539]\n",
      "converged at iter 79 w/w of [0.34498468 0.63880983 0.74924939 0.82019541 0.87015882]\n",
      "converged at iter 61 w/w of [0.1754303  0.40833222 0.54146838 0.68329403 0.88356036]\n",
      "converged at iter 62 w/w of [0.14807791 0.5065224  0.65878722 0.81928805 0.95891022]\n",
      "converged at iter 66 w/w of [0.1825122  0.48221955 0.65672505 0.96215503 0.98612137]\n",
      "converged at iter 72 w/w of [0.09639882 0.26905495 0.41892637 0.73199882 0.8605055 ]\n",
      "converged at iter 62 w/w of [0.16085144 0.39051935 0.56259677 0.75618553 0.96433881]\n",
      "converged at iter 63 w/w of [0.25763594 0.44394151 0.57454532 0.72640604 0.90801846]\n",
      "converged at iter 74 w/w of [0.21033466 0.51907484 0.75619763 0.90297459 0.95957667]\n",
      "converged at iter 54 w/w of [0.03438207 0.0760785  0.17117403 0.25082551 0.35148334]\n",
      "converged at iter 113 w/w of [0.04660301 0.10569883 0.27955799 0.4676024  0.96799587]\n",
      "converged at iter 84 w/w of [0.04272828 0.15368533 0.4304073  0.80826714 0.90594804]\n",
      "converged at iter 55 w/w of [0.0567384  0.15771516 0.28477004 0.39414014 0.58776594]\n",
      "converged at iter 63 w/w of [0.15810198 0.34697154 0.50265795 0.64396542 0.86209031]\n",
      "converged at iter 59 w/w of [0.07016081 0.19661947 0.40954601 0.64613996 0.77579909]\n",
      "converged at iter 63 w/w of [0.32952803 0.5163106  0.61859679 0.75843008 0.89602128]\n",
      "converged at iter 79 w/w of [0.14593409 0.27751633 0.34524009 0.61292256 0.77980038]\n",
      "converged at iter 85 w/w of [0.3819064  0.59868831 0.77606663 0.84560263 0.89587664]\n",
      "converged at iter 82 w/w of [0.06761606 0.22421506 0.43803302 0.64531488 0.95849399]\n",
      "converged at iter 58 w/w of [0.0772665  0.14045683 0.35592623 0.58529912 0.76749531]\n",
      "converged at iter 61 w/w of [0.17886799 0.37173695 0.49730877 0.5807718  0.75550777]\n",
      "converged at iter 69 w/w of [0.26792858 0.62526521 0.73723856 0.82976961 0.94881118]\n",
      "converged at iter 82 w/w of [0.248606   0.58454145 0.83098786 0.93789531 0.98300007]\n",
      "converged at iter 63 w/w of [0.13207807 0.32945275 0.49692589 0.60606895 0.80127193]\n",
      "converged at iter 66 w/w of [0.21402552 0.44989792 0.5260395  0.62447921 0.82842498]\n",
      "converged at iter 113 w/w of [0.07162854 0.19938571 0.31203726 0.75708142 0.96799587]\n",
      "converged at iter 63 w/w of [0.16293932 0.3793238  0.53477191 0.7173823  0.86643662]\n",
      "converged at iter 59 w/w of [0.12160376 0.39880078 0.56672286 0.77908412 0.90382055]\n",
      "converged at iter 67 w/w of [0.19449193 0.3606951  0.44366396 0.55803285 0.75161557]\n",
      "converged at iter 75 w/w of [0.08205612 0.1824651  0.39375321 0.58893125 0.86232652]\n",
      "converged at iter 60 w/w of [0.12681793 0.29388101 0.45989988 0.61692363 0.80580038]\n",
      "converged at iter 63 w/w of [0.1775851  0.31607087 0.4447668  0.57178696 0.77391084]\n",
      "converged at iter 61 w/w of [0.16756252 0.2692359  0.42706271 0.57347714 0.74004717]\n",
      "converged at iter 61 w/w of [0.1300543  0.30276748 0.50531409 0.66369853 0.88259016]\n",
      "converged at iter 64 w/w of [0.         0.16376255 0.51116949 0.79477781 0.95798238]\n",
      "converged at iter 65 w/w of [0.29517152 0.40571147 0.53202226 0.69195252 0.9268717 ]\n",
      "converged at iter 92 w/w of [0.0496685  0.16648684 0.35434893 0.69650953 0.97661413]\n",
      "converged at iter 64 w/w of [0.11887783 0.28066488 0.52711446 0.69363225 0.88223429]\n",
      "converged at iter 69 w/w of [0.12520143 0.28244174 0.44301051 0.5983912  0.78092718]\n",
      "converged at iter 55 w/w of [0.05197135 0.1991899  0.46377804 0.62819483 0.79711067]\n",
      "converged at iter 72 w/w of [0.08066498 0.21620046 0.34594172 0.53850452 0.83787132]\n",
      "converged at iter 63 w/w of [0.08039497 0.22152678 0.34435514 0.49735239 0.75595932]\n",
      "converged at iter 60 w/w of [0.17097476 0.40801798 0.60957328 0.75212939 0.86258606]\n",
      "converged at iter 53 w/w of [0.13744891 0.28246208 0.47402033 0.56274237 0.68375984]\n",
      "converged at iter 78 w/w of [0.34964242 0.67911948 0.76596789 0.87737608 0.93835023]\n",
      "converged at iter 63 w/w of [0.26372823 0.50806229 0.61977949 0.75744835 0.878046  ]\n",
      "converged at iter 76 w/w of [0.16540877 0.31694502 0.43136137 0.61349797 0.84889034]\n",
      "converged at iter 66 w/w of [0.09639103 0.3057662  0.53455113 0.76012474 0.89586088]\n",
      "converged at iter 65 w/w of [0.06692569 0.39291806 0.70789826 0.88080283 0.97982448]\n",
      "converged at iter 67 w/w of [0.1100031  0.22383426 0.44864845 0.67683313 0.93307122]\n",
      "converged at iter 68 w/w of [0.09846112 0.27507768 0.47259646 0.62773188 0.85456998]\n",
      "converged at iter 50 w/w of [0.04192902 0.07510726 0.4295743  0.58127122 0.69409543]\n",
      "converged at iter 49 w/w of [0.05009139 0.17696883 0.2760897  0.3761489  0.47021245]\n",
      "converged at iter 55 w/w of [0.05249936 0.15316628 0.35124766 0.56152662 0.6740958 ]\n",
      "converged at iter 75 w/w of [0.03879409 0.16036648 0.236041   0.3996445  0.56850997]\n",
      "\n",
      "lambda= 0.9\n",
      "converged at iter 53 w/w of [0.06767658 0.28971602 0.56036944 0.66085995 0.79854176]\n",
      "converged at iter 78 w/w of [0.08587547 0.22942907 0.52958717 0.75567235 0.98170042]\n",
      "converged at iter 43 w/w of [0.11183709 0.32912337 0.50871851 0.65306546 0.84971755]\n",
      "converged at iter 56 w/w of [0.33860203 0.44221593 0.55506784 0.78577566 0.97604306]\n",
      "converged at iter 61 w/w of [0.01964945 0.1530649  0.30867223 0.48792245 0.73606898]\n",
      "converged at iter 61 w/w of [0.17369621 0.56598013 0.72589796 0.89319962 0.98548126]\n",
      "converged at iter 67 w/w of [0.25927616 0.57530974 0.81218429 0.96036323 0.98080415]\n",
      "converged at iter 40 w/w of [0.10733717 0.1833354  0.3748386  0.64925357 0.7741256 ]\n",
      "converged at iter 38 w/w of [0.31573802 0.49972905 0.64420027 0.7796212  0.86542583]\n",
      "converged at iter 39 w/w of [0.01478043 0.02728796 0.36195024 0.51681958 0.740348  ]\n",
      "converged at iter 51 w/w of [0.3301713  0.44938394 0.53643298 0.60807023 0.82057294]\n",
      "converged at iter 52 w/w of [0.09038592 0.17587794 0.23677658 0.35627653 0.56739632]\n",
      "converged at iter 41 w/w of [0.08477183 0.21824474 0.3148567  0.44371566 0.65236273]\n",
      "converged at iter 39 w/w of [0.15334154 0.25919052 0.31929915 0.43274545 0.64193835]\n",
      "converged at iter 55 w/w of [0.08429526 0.18877756 0.39487789 0.599834   0.85376001]\n",
      "converged at iter 51 w/w of [0.20775802 0.50935707 0.59682747 0.71384374 0.90829486]\n",
      "converged at iter 48 w/w of [0.44276131 0.55916831 0.65227558 0.83777804 0.96967839]\n",
      "converged at iter 39 w/w of [0.1345677  0.26027296 0.58072549 0.67723949 0.74697324]\n",
      "converged at iter 51 w/w of [0.09844737 0.33384348 0.51761938 0.67935828 0.74650993]\n",
      "converged at iter 62 w/w of [0.42586405 0.59939058 0.71130495 0.8952447  0.9737806 ]\n",
      "converged at iter 56 w/w of [0.16094648 0.25861359 0.44495345 0.64766953 0.85981143]\n",
      "converged at iter 41 w/w of [0.05761862 0.21165847 0.39902326 0.52555318 0.65451457]\n",
      "converged at iter 66 w/w of [0.02780954 0.13701786 0.4621089  0.75035499 0.85472293]\n",
      "converged at iter 76 w/w of [0.00680171 0.10545325 0.26425093 0.44861628 0.77999345]\n",
      "converged at iter 61 w/w of [0.05162972 0.41125243 0.70647818 0.88583904 0.97247913]\n",
      "converged at iter 52 w/w of [0.25476618 0.39860116 0.48057602 0.62930437 0.8907659 ]\n",
      "converged at iter 62 w/w of [0.126696   0.22053323 0.432046   0.85140119 0.98216317]\n",
      "converged at iter 41 w/w of [0.00810839 0.32216371 0.5687919  0.73973565 0.88295037]\n",
      "converged at iter 45 w/w of [0.02973464 0.36694778 0.6174802  0.80343461 0.87374828]\n",
      "converged at iter 69 w/w of [0.03680705 0.35514514 0.64303986 0.94520563 0.98369455]\n",
      "converged at iter 69 w/w of [0.24751268 0.32922096 0.49373575 0.76334201 0.98079551]\n",
      "converged at iter 47 w/w of [0.28789798 0.46867706 0.66920611 0.80866497 0.92565368]\n",
      "converged at iter 45 w/w of [0.24025198 0.48100242 0.59585552 0.68197772 0.84415895]\n",
      "converged at iter 61 w/w of [0.17339997 0.42701434 0.71086786 0.96258724 0.98634433]\n",
      "converged at iter 61 w/w of [0.         0.18219088 0.49358091 0.70300069 0.79174837]\n",
      "converged at iter 150 w/w of [0.13492428 0.21217262 0.23640518 0.40307094 0.95170398]\n",
      "converged at iter 88 w/w of [0.14111376 0.23957775 0.35346616 0.54920921 0.77636205]\n",
      "converged at iter 79 w/w of [0.2804338  0.73865011 0.7665757  0.81533602 0.98472374]\n",
      "converged at iter 42 w/w of [0.16568102 0.3629096  0.49110567 0.6306491  0.79633347]\n",
      "converged at iter 44 w/w of [0.26378872 0.385106   0.49914926 0.65610218 0.79261429]\n",
      "converged at iter 54 w/w of [0.28713266 0.5285824  0.68239046 0.8336993  0.92894595]\n",
      "converged at iter 51 w/w of [0.16290266 0.47060109 0.66125045 0.95056188 0.98787909]\n",
      "converged at iter 96 w/w of [0.00690978 0.02246119 0.09798612 0.33719396 0.92529683]\n",
      "converged at iter 63 w/w of [0.39045802 0.70975411 0.74631176 0.78735625 0.99166253]\n",
      "converged at iter 54 w/w of [0.40056718 0.57521293 0.6690877  0.83529664 0.97033689]\n",
      "converged at iter 45 w/w of [0.15006085 0.46017877 0.71377207 0.80778701 0.88254641]\n",
      "converged at iter 64 w/w of [0.4288677  0.75936696 0.85204626 0.91985756 0.94284411]\n",
      "converged at iter 50 w/w of [0.21180224 0.53883703 0.6812927  0.80883821 0.94380301]\n",
      "converged at iter 52 w/w of [0.14590825 0.57189576 0.73434775 0.88904482 0.98149308]\n",
      "converged at iter 55 w/w of [0.2549741  0.53666364 0.68826874 0.98967435 0.99781577]\n",
      "converged at iter 62 w/w of [0.10636295 0.29918748 0.43705691 0.71815214 0.85500662]\n",
      "converged at iter 56 w/w of [0.15358972 0.39595344 0.57758082 0.77927595 0.98040668]\n",
      "converged at iter 50 w/w of [0.2691779  0.44932484 0.56428895 0.69965476 0.89008055]\n",
      "converged at iter 57 w/w of [0.19680903 0.54864911 0.81016548 0.95951603 0.98585121]\n",
      "converged at iter 40 w/w of [0.02165876 0.04381945 0.15331563 0.22134764 0.27737382]\n",
      "converged at iter 113 w/w of [0.02064857 0.08098653 0.28444673 0.48616364 0.96799587]\n",
      "converged at iter 80 w/w of [0.01658928 0.13757342 0.46866824 0.91715037 0.94713713]\n",
      "converged at iter 40 w/w of [0.05863587 0.1380306  0.28282561 0.43716954 0.68452028]\n",
      "converged at iter 55 w/w of [0.19752667 0.46595963 0.58012299 0.67496367 0.87176636]\n",
      "converged at iter 45 w/w of [0.13394758 0.31755424 0.44088599 0.61325559 0.75863795]\n",
      "converged at iter 47 w/w of [0.39477238 0.57658591 0.65937691 0.80498927 0.93308343]\n",
      "converged at iter 62 w/w of [0.16516455 0.26942281 0.31260283 0.54702357 0.7367026 ]\n",
      "converged at iter 64 w/w of [0.43789406 0.65786917 0.80557303 0.87183484 0.91813958]\n",
      "converged at iter 79 w/w of [0.09508176 0.22280756 0.44620964 0.67966223 0.97459284]\n",
      "converged at iter 45 w/w of [0.07097095 0.13256786 0.34135746 0.58726032 0.80231987]\n",
      "converged at iter 50 w/w of [0.18684524 0.44031635 0.54001707 0.56477761 0.71487741]\n",
      "converged at iter 55 w/w of [0.29833544 0.70854114 0.81066635 0.89260579 0.96938494]\n",
      "converged at iter 60 w/w of [0.20753666 0.6117826  0.87766148 0.97606095 0.99172748]\n",
      "converged at iter 54 w/w of [0.12506391 0.36633954 0.53122772 0.60456274 0.76960283]\n",
      "converged at iter 59 w/w of [0.22855461 0.51890665 0.58030772 0.6255818  0.78523863]\n",
      "converged at iter 113 w/w of [0.09554726 0.19728089 0.29627201 0.74934115 0.96799587]\n",
      "converged at iter 50 w/w of [0.15615673 0.3557538  0.52354999 0.71897537 0.86455899]\n",
      "converged at iter 50 w/w of [0.12827394 0.41074941 0.5672965  0.76050074 0.89125748]\n",
      "converged at iter 57 w/w of [0.3191529  0.53147888 0.58223311 0.68321206 0.81044033]\n",
      "converged at iter 69 w/w of [0.04793695 0.12562833 0.39787688 0.65712772 0.93309059]\n",
      "converged at iter 50 w/w of [0.13275385 0.30473147 0.45868375 0.59867226 0.78827256]\n",
      "converged at iter 50 w/w of [0.135851   0.28321009 0.40693774 0.47533396 0.6859322 ]\n",
      "converged at iter 49 w/w of [0.11702322 0.19951265 0.38168586 0.50829896 0.64677167]\n",
      "converged at iter 55 w/w of [0.12458721 0.33224338 0.5478605  0.69495279 0.87964399]\n",
      "converged at iter 57 w/w of [0.         0.14097392 0.52281196 0.83592033 0.98024928]\n",
      "converged at iter 61 w/w of [0.24933362 0.37776481 0.51359051 0.65370655 0.91114016]\n",
      "converged at iter 92 w/w of [0.01678829 0.12279553 0.33486798 0.71055048 0.97661413]\n",
      "converged at iter 56 w/w of [0.11647317 0.23194219 0.51849643 0.71278653 0.88994396]\n",
      "converged at iter 60 w/w of [0.13732547 0.3317778  0.51502047 0.66827648 0.75864153]\n",
      "converged at iter 45 w/w of [0.02273233 0.18316554 0.44898646 0.62995103 0.83820731]\n",
      "converged at iter 67 w/w of [0.05301435 0.22323999 0.34772937 0.49859821 0.82766651]\n",
      "converged at iter 54 w/w of [0.05354146 0.20352391 0.31300455 0.44276631 0.74540855]\n",
      "converged at iter 48 w/w of [0.22392781 0.44227148 0.6210958  0.77246187 0.88765941]\n",
      "converged at iter 38 w/w of [0.15606711 0.29526    0.4366969  0.48168952 0.60539719]\n",
      "converged at iter 64 w/w of [0.44092795 0.80110318 0.8619987  0.95368024 0.97699403]\n",
      "converged at iter 46 w/w of [0.2911904  0.56984442 0.6668525  0.77146419 0.87189344]\n",
      "converged at iter 70 w/w of [0.13856977 0.3111927  0.44480766 0.65526787 0.90959617]\n",
      "converged at iter 54 w/w of [0.11114677 0.38422247 0.60595015 0.82306024 0.93720117]\n",
      "converged at iter 46 w/w of [0.02608412 0.38879663 0.76296384 0.94539515 0.99296779]\n",
      "converged at iter 62 w/w of [0.12108854 0.22720123 0.43345101 0.67147598 0.96606886]\n",
      "converged at iter 62 w/w of [0.10726207 0.31077633 0.50612284 0.66696598 0.89154144]\n",
      "converged at iter 33 w/w of [0.01927971 0.02792111 0.37617597 0.51725134 0.64387403]\n",
      "converged at iter 32 w/w of [0.0235977  0.15964114 0.25828299 0.31972263 0.40836919]\n",
      "converged at iter 40 w/w of [0.07056736 0.18809141 0.39097272 0.62213265 0.72777186]\n",
      "converged at iter 59 w/w of [0.04637462 0.21359482 0.27666555 0.36918707 0.51093491]\n",
      "\n",
      "lambda= 1\n",
      "converged at iter 51 w/w of [-3.22389737e-19  2.10521786e-01  5.14285714e-01  6.08694663e-01\n",
      "  7.39328132e-01]\n",
      "converged at iter 78 w/w of [0.09089883 0.22222218 0.53846154 0.78570817 0.98170042]\n",
      "converged at iter 38 w/w of [0.11974167 0.35598466 0.55172291 0.71998713 0.90954547]\n",
      "converged at iter 54 w/w of [0.42005804 0.53816967 0.57142688 0.76881381 0.98891993]\n",
      "converged at iter 58 w/w of [-1.46261785e-18  1.57893960e-01  3.66666666e-01  6.11104983e-01\n",
      "  8.44405943e-01]\n",
      "converged at iter 60 w/w of [0.19078604 0.61523997 0.76923076 0.93327899 0.98714782]\n",
      "converged at iter 58 w/w of [0.22657544 0.58298184 0.84615382 0.99999994 0.99997975]\n",
      "converged at iter 35 w/w of [0.08937002 0.08694726 0.27586035 0.59975661 0.76335276]\n",
      "converged at iter 30 w/w of [0.2646318  0.53124498 0.74358947 0.89281029 0.93248409]\n",
      "converged at iter 35 w/w of [-2.12152321e-19 -4.24304641e-19  3.04315426e-01  4.79979658e-01\n",
      "  7.63352757e-01]\n",
      "converged at iter 48 w/w of [0.32972866 0.43739852 0.53333331 0.63635943 0.87927643]\n",
      "converged at iter 46 w/w of [0.06662889 0.10810811 0.16666667 0.27774764 0.48920531]\n",
      "converged at iter 38 w/w of [2.10759252e-18 1.19997855e-01 2.42424183e-01 3.88682469e-01\n",
      " 6.28768674e-01]\n",
      "converged at iter 37 w/w of [0.23856886 0.30591268 0.28571278 0.42307079 0.68830353]\n",
      "converged at iter 52 w/w of [0.07140053 0.16666656 0.39393939 0.61904468 0.86354553]\n",
      "converged at iter 48 w/w of [0.24543169 0.58333222 0.63636363 0.68734053 0.87927643]\n",
      "converged at iter 45 w/w of [0.49563602 0.58333081 0.6666666  0.87465757 0.99127204]\n",
      "converged at iter 31 w/w of [0.11557389 0.24524771 0.49995583 0.53841397 0.63686522]\n",
      "converged at iter 47 w/w of [0.12251722 0.37489645 0.59259237 0.77770858 0.76853503]\n",
      "converged at iter 56 w/w of [0.48436385 0.6427191  0.73913011 0.9374461  0.99853499]\n",
      "converged at iter 52 w/w of [0.15373598 0.21739103 0.4137931  0.64701874 0.86354553]\n",
      "converged at iter 36 w/w of [0.07111538 0.23999237 0.42424219 0.54163893 0.65997884]\n",
      "converged at iter 65 w/w of [9.76549782e-20 1.05263039e-01 4.58333325e-01 7.49815314e-01\n",
      " 8.18400946e-01]\n",
      "converged at iter 73 w/w of [-5.69807510e-19  7.14273904e-02  2.27272724e-01  4.16629767e-01\n",
      "  7.81080347e-01]\n",
      "converged at iter 60 w/w of [-4.09194373e-19  3.84524982e-01  7.41935484e-01  9.49998544e-01\n",
      "  9.87147817e-01]\n",
      "converged at iter 49 w/w of [0.29828207 0.37931033 0.46666667 0.67999949 0.99015925]\n",
      "converged at iter 60 w/w of [0.0998203  0.17646813 0.42105127 0.88578911 0.98714782]\n",
      "converged at iter 36 w/w of [0.         0.38205845 0.62962207 0.79162613 0.91694028]\n",
      "converged at iter 41 w/w of [-1.43852316e-18  3.68355855e-01  6.45161131e-01  8.49909612e-01\n",
      "  9.01442034e-01]\n",
      "converged at iter 68 w/w of [-9.81757009e-19  3.99993653e-01  7.08333328e-01  9.99832189e-01\n",
      "  9.85116878e-01]\n",
      "converged at iter 68 w/w of [0.29976793 0.29999992 0.46428571 0.78568667 0.98511688]\n",
      "converged at iter 44 w/w of [0.32807679 0.47045879 0.63999796 0.76449554 0.89127204]\n",
      "converged at iter 40 w/w of [0.29556574 0.60867811 0.67647055 0.68178526 0.810447  ]\n",
      "converged at iter 60 w/w of [0.14102112 0.41647224 0.73683973 0.99908082 0.98714782]\n",
      "converged at iter 58 w/w of [0.         0.22128641 0.54999868 0.7855895  0.84440594]\n",
      "converged at iter 150 w/w of [0.21428571 0.31818182 0.27272727 0.33330228 0.95170398]\n",
      "converged at iter 85 w/w of [0.12499995 0.24       0.375      0.55537222 0.72665918]\n",
      "converged at iter 77 w/w of [0.30139573 0.79976025 0.76923077 0.79999997 0.99987323]\n",
      "converged at iter 38 w/w of [0.1963504  0.34615013 0.48780488 0.6666624  0.82685952]\n",
      "converged at iter 42 w/w of [0.36369892 0.40907889 0.475      0.6206893  0.76701326]\n",
      "converged at iter 49 w/w of [0.29828207 0.5999893  0.76923047 0.93300857 0.99015925]\n",
      "converged at iter 49 w/w of [0.18380106 0.46650429 0.67999949 0.9993828  0.99015925]\n",
      "converged at iter 92 w/w of [ 3.69154117e-19 -2.92167550e-18  7.40740741e-02  3.33330731e-01\n",
      "  9.76614135e-01]\n",
      "converged at iter 56 w/w of [0.48436385 0.83332091 0.775      0.76923073 0.99062183]\n",
      "converged at iter 42 w/w of [0.36369892 0.54995321 0.65624994 0.84615112 0.99933972]\n",
      "converged at iter 41 w/w of [0.13556756 0.46607075 0.7142847  0.80947241 0.90144203]\n",
      "converged at iter 56 w/w of [0.48436385 0.84209895 0.93023256 1.         0.99999956]\n",
      "converged at iter 45 w/w of [0.27128755 0.67999838 0.81081081 0.91303636 0.99127204]\n",
      "converged at iter 49 w/w of [0.13877802 0.61107455 0.78571421 0.93731733 0.99015925]\n",
      "converged at iter 50 w/w of [0.31822309 0.57112526 0.69999001 0.99983633 0.99946921]\n",
      "converged at iter 58 w/w of [0.09977815 0.29999928 0.4347825  0.69844703 0.84440594]\n",
      "converged at iter 54 w/w of [0.19932372 0.43478229 0.63333333 0.86653286 0.98891993]\n",
      "converged at iter 48 w/w of [0.21981911 0.4090882  0.54545454 0.68418283 0.87927643]\n",
      "converged at iter 46 w/w of [0.18110635 0.58170359 0.85714262 0.99999903 0.99943341]\n",
      "converged at iter 33 w/w of [ 1.51258586e-18 -7.17375383e-19  1.21211900e-01  1.81768206e-01\n",
      "  2.12333198e-01]\n",
      "converged at iter 113 w/w of [1.20047629e-19 5.88235294e-02 2.85714286e-01 4.99996624e-01\n",
      " 9.67995874e-01]\n",
      "converged at iter 78 w/w of [-8.17295334e-19  1.33332917e-01  4.99999905e-01  9.98502211e-01\n",
      "  9.81700416e-01]\n",
      "converged at iter 35 w/w of [0.08937002 0.09521322 0.25       0.45945942 0.76335276]\n",
      "converged at iter 52 w/w of [0.22057429 0.56243504 0.65384605 0.70583862 0.86354553]\n",
      "converged at iter 39 w/w of [0.24032468 0.49860553 0.45832303 0.52617383 0.71954757]\n",
      "converged at iter 42 w/w of [0.43598083 0.62499383 0.7027027  0.86955036 0.99251175]\n",
      "converged at iter 55 w/w of [0.1665193  0.22727246 0.26086942 0.49847837 0.70108996]\n",
      "converged at iter 56 w/w of [0.48436385 0.71413233 0.84375    0.91176471 0.94999645]\n",
      "converged at iter 78 w/w of [0.12481278 0.19999938 0.42857143 0.68749915 0.98170042]\n",
      "converged at iter 40 w/w of [0.07125725 0.14284566 0.3333322  0.57138265 0.810447  ]\n",
      "converged at iter 45 w/w of [0.18085837 0.58333081 0.64864865 0.56521298 0.65709976]\n",
      "converged at iter 50 w/w of [0.31822309 0.76189896 0.86842105 0.95651972 0.99484622]\n",
      "converged at iter 46 w/w of [0.18110635 0.63337381 0.90908102 0.99967126 0.99214483]\n",
      "converged at iter 51 w/w of [0.09067059 0.31818082 0.48484848 0.54999372 0.73932813]\n",
      "converged at iter 55 w/w of [0.22098039 0.57692304 0.62162162 0.58821446 0.70108996]\n",
      "converged at iter 113 w/w of [0.1111085  0.1875     0.27777778 0.74255764 0.96799587]\n",
      "converged at iter 43 w/w of [0.10918564 0.26086613 0.38888889 0.54544205 0.79137979]\n",
      "converged at iter 48 w/w of [0.15811628 0.44441202 0.57142849 0.73303313 0.87927643]\n",
      "converged at iter 52 w/w of [0.45348411 0.74074068 0.75       0.81817981 0.86354553]\n",
      "converged at iter 68 w/w of [-1.02087971e-18  5.88233445e-02  3.92857143e-01  7.05880135e-01\n",
      "  9.85116878e-01]\n",
      "converged at iter 47 w/w of [0.12251722 0.35288567 0.48275857 0.57891843 0.76853503]\n",
      "converged at iter 43 w/w of [0.09030322 0.24998299 0.37036988 0.35282421 0.54592819]\n",
      "converged at iter 43 w/w of [-7.02307606e-19  7.99996606e-02  3.12499980e-01  4.21003745e-01\n",
      "  5.45928192e-01]\n",
      "converged at iter 52 w/w of [0.11028714 0.3332621  0.57692299 0.7221984  0.86354553]\n",
      "converged at iter 54 w/w of [0.         0.12361499 0.52630977 0.85689399 0.98891993]\n",
      "converged at iter 58 w/w of [0.07689919 0.22222222 0.39393939 0.49997972 0.84440594]\n",
      "converged at iter 92 w/w of [-6.11371342e-19  9.52380952e-02  3.18181818e-01  7.13385588e-01\n",
      "  9.76614135e-01]\n",
      "converged at iter 52 w/w of [-1.19537986e-18  8.32252104e-02  4.81481444e-01  6.99993606e-01\n",
      "  8.63545528e-01]\n",
      "converged at iter 55 w/w of [0.09075945 0.31999996 0.56410256 0.72727188 0.70108996]\n",
      "converged at iter 41 w/w of [2.16126811e-18 1.65784322e-01 4.34772962e-01 6.49930880e-01\n",
      " 9.01442034e-01]\n",
      "converged at iter 65 w/w of [3.08093161e-19 1.90476148e-01 3.07692307e-01 4.16564063e-01\n",
      " 8.18400946e-01]\n",
      "converged at iter 51 w/w of [3.24551673e-18 1.30434571e-01 2.49999999e-01 3.88873245e-01\n",
      " 7.39328132e-01]\n",
      "converged at iter 43 w/w of [0.27310476 0.46623612 0.6333332  0.80769038 0.92715482]\n",
      "converged at iter 32 w/w of [0.19313263 0.35203294 0.40624823 0.39284646 0.53221311]\n",
      "converged at iter 56 w/w of [0.48436385 0.87999991 0.925      0.99999979 0.99958972]\n",
      "converged at iter 38 w/w of [0.32407673 0.62498152 0.70588225 0.76180665 0.82685952]\n",
      "converged at iter 68 w/w of [0.07691714 0.2962963  0.46875    0.71426061 0.98511688]\n",
      "converged at iter 49 w/w of [0.12289858 0.46103652 0.69998751 0.92799832 0.99015925]\n",
      "converged at iter 39 w/w of [1.46502810e-18 3.93430719e-01 8.14811007e-01 9.99962577e-01\n",
      " 9.93163651e-01]\n",
      "converged at iter 60 w/w of [0.12416019 0.23071499 0.40909077 0.64278163 0.98714782]\n",
      "converged at iter 60 w/w of [0.11072364 0.35293625 0.55555555 0.74997853 0.98714782]\n",
      "converged at iter 26 w/w of [0.         0.         0.33324016 0.45158374 0.58360529]\n",
      "converged at iter 22 w/w of [-2.83466030e-19  1.15231420e-01  2.05860294e-01  2.14130007e-01\n",
      "  2.89239677e-01]\n",
      "converged at iter 31 w/w of [0.11557389 0.28305121 0.45824078 0.6954415  0.79481108]\n",
      "converged at iter 48 w/w of [1.63800718e-18 1.99999799e-01 2.66666657e-01 2.85509237e-01\n",
      " 4.15412978e-01]\n"
     ]
    }
   ],
   "source": [
    "#2. Calculate TD Lambda (with various lambdas) with updates per dataset until convergence (store predicted weights for 100 datasets).\n",
    "verbose = False\n",
    "\n",
    "#alpha - learning rate, fix for all figure simulations\n",
    "alpha = fig3_alpha\n",
    "\n",
    "#lambd = lambda, eligibility trace\n",
    "lambdas = [0, 0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    "\n",
    "experiment1_rmses = []\n",
    "\n",
    "for lambd in lambdas:\n",
    "    \n",
    "    #datasets_w - weights matrix, non terminal state weights per dataset    \n",
    "    datasets_w = np.zeros((len(S_non_terminal), len(datasets)))\n",
    "\n",
    "    print('\\nlambda=', lambd)\n",
    "    for idx, dataset in enumerate(datasets):\n",
    "\n",
    "        #w - weight vector (of predicted return) of s_non_terminal\n",
    "        w = np.zeros(len(S_non_terminal))\n",
    "\n",
    "        iter_counter = 0  \n",
    "        while True:                                                         # Iter over dataset - until convergence\n",
    "\n",
    "            iter_counter += 1\n",
    "\n",
    "            if iter_counter > 10000:\n",
    "                raise ValueError(\"Learner fails to converge after {} timesteps.  Something's wrong with the code.\".format(iter_counter))\n",
    "\n",
    "            #w_delta - weight update term, sequence level\n",
    "            w_delta = np.zeros(len(S_non_terminal))\n",
    "\n",
    "            for seq in dataset:\n",
    "\n",
    "                #eligibility - eligibility trace\n",
    "                eligibility = np.zeros(len(S_non_terminal))\n",
    "\n",
    "                #z - return\n",
    "                z = R[seq[-1]]\n",
    "\n",
    "                if verbose:\n",
    "                    print('seq', seq)\n",
    "                    print('z', z)\n",
    "\n",
    "                for t, S_t in enumerate(seq[:-1]):\n",
    "\n",
    "                    #x_t - observation vector\n",
    "                    x_t = (np.array(S_non_terminal) == S_t).astype(int)\n",
    "\n",
    "                    S_t_1 = seq[t+1]\n",
    "                    x_t_1 = (np.array(S_non_terminal) == S_t_1).astype(int)\n",
    "\n",
    "                    eligibility *= lambd\n",
    "                    eligibility += x_t\n",
    "\n",
    "                    if t == len(seq[:-1])-1:\n",
    "                        #td_error - td error, when S_t is last non-terminal state\n",
    "                        td_error = (z - np.dot(w, x_t))\n",
    "\n",
    "                    else:\n",
    "                        #td_error - td error otherwise\n",
    "                        td_error = (np.dot(w, x_t_1 - x_t))                    \n",
    "\n",
    "                    #w_delta_t - weight update term, sequence level per S_t\n",
    "                    w_delta_t =  alpha * td_error * eligibility\n",
    "\n",
    "                    w_delta += w_delta_t\n",
    "                    if verbose:\n",
    "    #                     print('S_t', S_t)\n",
    "                        print('x_t', x_t)  \n",
    "                        print('TD Error', td_error)\n",
    "                        print('w_delta_t', w_delta_t)\n",
    "\n",
    "            w += w_delta \n",
    "\n",
    "            if np.max(np.abs(w_delta)) < 0.001: \n",
    "                print('converged at iter {0} w/w of {1}'.format(iter_counter,w))\n",
    "                datasets_w[:, idx] = w\n",
    "                break\n",
    "                \n",
    "    #P_ideal - Ideal Predictions for non terminal states\n",
    "    P_ideal = [1/6, 1/3, 1/2, 2/3, 5/6]\n",
    "\n",
    "    #P_rmse = rmse(P_pred, P_ideal), where P_pred - Predictions for non terminal states\n",
    "    P_pred_rmse = np.mean(np.apply_along_axis(lambda P_pred: rmse(P_pred, P_ideal), 0, datasets_w))\n",
    "\n",
    "    experiment1_rmses.append(P_pred_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3. Plot RMS error (root mean squared error) given ideal predictions in Sutton.\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "plt.title('RMSE for TD Methods vs. Supervised WH Procedure')\n",
    "\n",
    "plt.plot(lambdas, experiment1_rmses, '-ro')\n",
    "fig.gca().set_xlabel(r'$\\lambda$')\n",
    "fig.gca().set_ylabel(r'$RMSE$')\n",
    "\n",
    "ax.annotate('Widrow-Hoff', (lambdas[-1], experiment1_rmses[-1]))\n",
    "\n",
    "\n",
    "\n",
    "fig.savefig('img/Project1-Fig3-REPRODUCED.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Figure 4] Experiment 2 - TD Methods vs WH on learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"This experiment concerns the question of the **learning rate** when the training set is presented just once rather than repeatedly until convergence.\"\n",
    "\n",
    "#### Graph to reproduce:\n",
    "\n",
    "<img src=\"img/Project1-Fig4.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha - learning rate, fix alpha for figure 4\n",
    "fig4_alphas = np.append(0.01, np.arange(0.00, .65, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.22198221828066392\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.1742220236327757\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.12842316733396428\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.09814989819394108\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.08442790259432878\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.08803738060743731\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.11016351836349564\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.1521925414862465\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.22099095283101472\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.3351519638402564\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.5526721398980535\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.9673945930160248\n",
      "\n",
      "lambda= 0\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 1.7748798952314657\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2196232808326462\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.16512430407389075\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.11704524089459571\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.08963108991491803\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.08161014235775228\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.08910870487451622\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.10504295910117678\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.12711586230533442\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.15719279822995613\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.19809899228036837\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.25767971225538366\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.3514436674554772\n",
      "\n",
      "lambda= 0.3\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.5014170550853259\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.21388945029187223\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.15106649797909136\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.11729037269127478\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.11868331419183026\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.13839706600547988\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.16401623245781877\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.191679221001402\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.22206299654808917\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.2585135985137061\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.3053216467421382\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.36635167459142415\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.446159515972417\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.5524166024890935\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2128786858242728\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.18384469188839142\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.21051493500354707\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.2604350019992159\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.3150423080842395\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.3717759683127005\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.4343923316347884\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.5129682303565377\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.6178414502794489\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.762771485293838\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.9597031606628902\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 1.2317842167856075\n",
      "\n",
      "lambda= 1\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 1.6325175139252521\n"
     ]
    }
   ],
   "source": [
    "#1. Calculate TD Lambda (with various lambdas and alphas) with updates per sequence, single presentation (no convergence) (store mean for 100 datasets).\n",
    "verbose = False\n",
    "\n",
    "#lambd = lambda, eligibility trace\n",
    "lambdas = [0, 0.3, 0.8, 1]\n",
    "\n",
    "experiment2a_rmses = []\n",
    "\n",
    "for lambd in lambdas:\n",
    "    \n",
    "    lambda_rmses = []\n",
    "    \n",
    "    for alpha in fig4_alphas:\n",
    "    \n",
    "        print('\\nlambda=', lambd)\n",
    "        print('\\nalpha=', alpha)\n",
    "        \n",
    "        #datasets_w - weights matrix, non terminal state weights per dataset    \n",
    "        datasets_w = np.zeros((len(S_non_terminal), len(datasets)))\n",
    "\n",
    "        for idx, dataset in enumerate(datasets):\n",
    "\n",
    "            #w - weight vector (of predicted return) of s_non_terminal, SET TO 0.5 TO PREVENT BIAS TO LEFT OR RIGHT TEMRINATIONS\n",
    "            w = np.full(len(S_non_terminal), 0.5)\n",
    "\n",
    "            for seq in dataset:\n",
    "                \n",
    "                #w_delta - weight update term, sequence level\n",
    "                w_delta = np.zeros(len(S_non_terminal))\n",
    "\n",
    "                #eligibility - eligibility trace\n",
    "                eligibility = np.zeros(len(S_non_terminal))\n",
    "\n",
    "                #z - return\n",
    "                z = R[seq[-1]]\n",
    "\n",
    "                if verbose:\n",
    "                    print('seq', seq)\n",
    "                    print('z', z)\n",
    "\n",
    "                for t, S_t in enumerate(seq[:-1]):\n",
    "\n",
    "                    #x_t - observation vector\n",
    "                    x_t = (np.array(S_non_terminal) == S_t).astype(int)\n",
    "\n",
    "                    S_t_1 = seq[t+1]\n",
    "                    x_t_1 = (np.array(S_non_terminal) == S_t_1).astype(int)\n",
    "                    \n",
    "                    eligibility *= lambd\n",
    "                    eligibility += x_t\n",
    "\n",
    "                    if t == len(seq[:-1])-1:\n",
    "                        #td_error - td error, when S_t is last non-terminal state\n",
    "                        td_error = (z - np.dot(w, x_t))\n",
    "\n",
    "                    else:\n",
    "                        #td_error - td error otherwise\n",
    "                        td_error = (np.dot(w, x_t_1 - x_t))                    \n",
    "\n",
    "                    #w_delta_t - weight update term, sequence level per S_t\n",
    "                    w_delta_t =  alpha * td_error * eligibility\n",
    "\n",
    "                    w_delta += w_delta_t\n",
    "                    if verbose:\n",
    "    #                     print('S_t', S_t)\n",
    "#                         print('x_t', x_t)  \n",
    "                        print('TD Error', td_error)\n",
    "#                         print('w_delta_t', w_delta_t)\n",
    "\n",
    "                #weight updates performed per sequence\n",
    "                w += w_delta \n",
    "        \n",
    "            #store w\n",
    "            datasets_w[:, idx] = w\n",
    "\n",
    "        #P_ideal - Ideal Predictions for non terminal states\n",
    "        P_ideal = [1/6, 1/3, 1/2, 2/3, 5/6]\n",
    "\n",
    "        #P_rmse = rmse(P_pred, P_ideal), where P_pred - Predictions for non terminal states\n",
    "        P_pred_rmse = np.mean(np.apply_along_axis(lambda P_pred: rmse(P_pred, P_ideal), 0, datasets_w))\n",
    "        \n",
    "        print('RMSE of {}'.format(P_pred_rmse))\n",
    "\n",
    "        lambda_rmses.append(P_pred_rmse)\n",
    "\n",
    "    experiment2a_rmses.append(lambda_rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3. Plot RMS error (root mean squared error) given ideal predictions in Sutton.\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "plt.title('RMSE for TD Methods vs. Supervised WH Procedure w/Different Alphas')\n",
    "\n",
    "for i, vec in enumerate(np.array(experiment2a_rmses)):\n",
    "    plot_cutoffs = [.55, .6, .6, .45]\n",
    "    mask = fig4_alphas < plot_cutoffs[i]\n",
    "    ax.plot(fig4_alphas[mask], vec[mask], label=lambdas[i], marker='o')\n",
    "    \n",
    "fig.gca().legend(title=r'$\\lambda$')\n",
    "fig.gca().set_xlabel(r'$\\alpha$')\n",
    "fig.gca().set_ylabel(r'$RMSE$')\n",
    "\n",
    "ax.set_ylim([0.0, 0.7])\n",
    "\n",
    "fig.savefig('img/Project1-Fig4-REPRODUCED.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Figure 5] Experiment 2 Part 2 - TD Methods vs WH on learning rate, BEST alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \"This experiment concerns the question of the **learning rate** when the training set is presented just once rather than repeatedly until convergence.\"\n",
    "\n",
    "#### Graph to reproduce:\n",
    "\n",
    "<img src=\"img/Project1-Fig5.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha - learning rate, fix alpha for figure 4\n",
    "fig4_alphas = np.append(0.01, np.arange(0.05, .65, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.22191255023153247\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.17393762140833147\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.12803770193913735\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.0977962214475143\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.08416195429612347\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.08769351701363093\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.10915057600185732\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.14957087120769716\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.21520877508808478\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.322956352759002\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.5262573910569616\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.90984953978425\n",
      "\n",
      "lambda= 0.01\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 1.646762188353966\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2212605377143402\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.17131966094103568\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.12456319056202307\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.0947778531780874\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.08226542664948722\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.08607078522744598\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.1035806506297217\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.1337536649547651\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.17948444480956208\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.24818415742354547\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.3656972829345446\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.5784999850506904\n",
      "\n",
      "lambda= 0.1\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.9692926844265745\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2204775761362413\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.16828601332825155\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.12073553815323113\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.09186194966309685\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.08123978900701165\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.08657823853370651\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.10254727154658617\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.12738640151541272\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.16273003233505723\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.21248850519000917\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.2892375006902892\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.41730171864452553\n",
      "\n",
      "lambda= 0.2\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.6340226945903203\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2196232808326462\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.16512430407389075\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.11704524089459571\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.08963108991491803\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.0816101423577523\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.08910870487451622\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.1050429591011768\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.1271158623053344\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.1571927982299561\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.19809899228036837\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.25767971225538366\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.3514436674554772\n",
      "\n",
      "lambda= 0.30000000000000004\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.5014170550853259\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2186860076049251\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.1618528436713655\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.11367245678819643\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.08847146671462944\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.08387037013251514\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.09384107006616321\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.11046394222036535\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.13144523702280883\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.15848078161749493\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.19483720640761054\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.24682587047603402\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.3246841282585653\n",
      "\n",
      "lambda= 0.4\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.44162365657734604\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.21765264916175933\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.15852398317498462\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.11093894376938979\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.08902910766838708\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.08873881952791367\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.1014071935199838\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.11919597917730201\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.14040688615272987\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.1668179760312405\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.20168983351864486\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.2501764953562969\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.3202049606093278\n",
      "\n",
      "lambda= 0.5\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.4211048332619042\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2165099563540146\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.1552713206907096\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.10945969262151062\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.09243645367177052\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.09742169190549724\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.11325750322538657\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.13281166852399592\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.15538567568791936\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.18331906796925448\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.21957149021997327\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.26846353450269406\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.33666992286025615\n",
      "\n",
      "lambda= 0.6\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.43238212862441344\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.21524964703618338\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.15244347901873886\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.11053061121686801\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.10083104652653127\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.11228680966858079\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.1320923847606905\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.15460952168791703\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.1799467926556229\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.21090178799896114\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.25084854879129603\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.30351356877586694\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.37419880546538564\n",
      "\n",
      "lambda= 0.7000000000000001\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.47092548221842606\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.21388945029187223\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.15106649797909136\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.11729037269127478\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.11868331419183026\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.13839706600547988\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.16401623245781877\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.191679221001402\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.22206299654808917\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.2585135985137061\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.3053216467421382\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.36635167459142415\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.446159515972417\n",
      "\n",
      "lambda= 0.8\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.5524166024890935\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2125917863274571\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.15489562458031086\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.13880997963452027\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.15762079808816992\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.1894220710804987\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.2244007656318988\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.26133671078156623\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.30200323266314943\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.35019009850070565\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.4119743158093266\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.49306324254253786\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 0.5998427042781952\n",
      "\n",
      "lambda= 0.9\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 0.7431089297871714\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.01\n",
      "RMSE of 0.2128786858242728\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.0\n",
      "RMSE of 0.23570226039551584\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.05\n",
      "RMSE of 0.18384469188839142\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.1\n",
      "RMSE of 0.21051493500354707\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.15000000000000002\n",
      "RMSE of 0.2604350019992159\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.2\n",
      "RMSE of 0.3150423080842395\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.25\n",
      "RMSE of 0.3717759683127005\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.30000000000000004\n",
      "RMSE of 0.4343923316347884\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.35000000000000003\n",
      "RMSE of 0.5129682303565377\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.4\n",
      "RMSE of 0.6178414502794489\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.45\n",
      "RMSE of 0.762771485293838\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.5\n",
      "RMSE of 0.9597031606628902\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.55\n",
      "RMSE of 1.2317842167856075\n",
      "\n",
      "lambda= 1.0\n",
      "\n",
      "alpha= 0.6000000000000001\n",
      "RMSE of 1.6325175139252521\n"
     ]
    }
   ],
   "source": [
    "#1. Calculate TD Lambda (with various lambdas and alphas) with updates per sequence, single presentation (no convergence) (store mean for 100 datasets).\n",
    "verbose = False\n",
    "\n",
    "#lambd = lambda, eligibility trace\n",
    "lambdas = np.append(0.01, np.arange(0.1, 1.1, .1))\n",
    "\n",
    "experiment2b_rmses = np.zeros((len(lambdas), len(fig4_alphas)))\n",
    "\n",
    "for lambd in lambdas:\n",
    "    \n",
    "    for alpha in fig4_alphas:\n",
    "    \n",
    "        print('\\nlambda=', lambd)\n",
    "        print('\\nalpha=', alpha)\n",
    "        \n",
    "        #datasets_w - weights matrix, non terminal state weights per dataset    \n",
    "        datasets_w = np.zeros((len(S_non_terminal), len(datasets)))\n",
    "\n",
    "        for idx, dataset in enumerate(datasets):\n",
    "\n",
    "            #w - weight vector (of predicted return) of s_non_terminal, SET TO 0.5 TO PREVENT BIAS TO LEFT OR RIGHT TEMRINATIONS\n",
    "            w = np.full(len(S_non_terminal), 0.5)\n",
    "\n",
    "\n",
    "            for seq in dataset:\n",
    "                \n",
    "                #w_delta - weight update term, sequence level\n",
    "                w_delta = np.zeros(len(S_non_terminal))\n",
    "\n",
    "                #eligibility - eligibility trace\n",
    "                eligibility = np.zeros(len(S_non_terminal))\n",
    "\n",
    "                #z - return\n",
    "                z = R[seq[-1]]\n",
    "\n",
    "                if verbose:\n",
    "                    print('seq', seq)\n",
    "                    print('z', z)\n",
    "\n",
    "                for t, S_t in enumerate(seq[:-1]):\n",
    "\n",
    "                    #x_t - observation vector\n",
    "                    x_t = (np.array(S_non_terminal) == S_t).astype(int)\n",
    "\n",
    "                    S_t_1 = seq[t+1]\n",
    "                    x_t_1 = (np.array(S_non_terminal) == S_t_1).astype(int)\n",
    "\n",
    "                    eligibility *= lambd\n",
    "                    eligibility += x_t\n",
    "\n",
    "                    if t == len(seq[:-1])-1:\n",
    "                        #td_error - td error, when S_t is last non-terminal state\n",
    "                        td_error = (z - np.dot(w, x_t))\n",
    "\n",
    "                    else:\n",
    "                        #td_error - td error otherwise\n",
    "                        td_error = (np.dot(w, x_t_1 - x_t))                    \n",
    "\n",
    "                    #w_delta_t - weight update term, sequence level per S_t\n",
    "                    w_delta_t =  alpha * td_error * eligibility\n",
    "\n",
    "                    w_delta += w_delta_t\n",
    "                    if verbose:\n",
    "    #                     print('S_t', S_t)\n",
    "#                         print('x_t', x_t)  \n",
    "                        print('TD Error', td_error)\n",
    "#                         print('w_delta_t', w_delta_t)\n",
    "\n",
    "                #weight updates performed per sequence\n",
    "                w += w_delta \n",
    "        \n",
    "            #store w\n",
    "            datasets_w[:, idx] = w\n",
    "\n",
    "        #P_ideal - Ideal Predictions for non terminal states\n",
    "        P_ideal = [1/6, 1/3, 1/2, 2/3, 5/6]\n",
    "\n",
    "        #P_rmse = rmse(P_pred, P_ideal), where P_pred - Predictions for non terminal states\n",
    "        P_pred_rmse = np.mean(np.apply_along_axis(lambda P_pred: rmse(P_pred, P_ideal), 0, datasets_w))\n",
    "        \n",
    "        print('RMSE of {}'.format(P_pred_rmse))\n",
    "\n",
    "        experiment2b_rmses[list(lambdas).index(lambd), list(fig4_alphas).index(alpha)] = P_pred_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo8AAAHyCAYAAACKxCT5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd5xddZ3/8dcnk947kEJoKYQQKSEU6SjFBigoKAI2EJe1rf5WLKCoWFjrimtbCwiisoCosICZ0IsEAgkhEwghkAKZhPSemfn+/jh32JthkrkTZubcmXk9H495zL2nfu65Z+59z/ec8z2RUkKSJEkqRZe8C5AkSVL7YXiUJElSyQyPkiRJKpnhUZIkSSUzPEqSJKlkhkdJkiSVzPCodiEiJkbEjBZc3j0R8dGWWl5LiIjjI2JxS0/byLy7RcTciOixk2l6RcRfI2JNRPx5V9bTXkXEhRHxQAsta5ffp84qIo6JiHmtsNyFEfGWll5ue9aS+7o6F8OjtlP4gN0UEesj4pWI+G1E9C0a/9uISBHxrgbz/bAw/MLC8+4R8b2IWFxY1gsR8YMdrKf+5yc7Ke3rwH+U+Bpy+UBsLx/EKaVlwHTgop1MdhawGzAkpXT2G1lfRHyg6D3eFBF1xe97YZr6/WFdRKyOiIci4uMRscPPqMI/ACki3tRg+K2F4ceXUNtehWm7vpHX2B5ExMCI+HXh73pdRDwbEf+ed10NpZTuTymNb6v1RcSREbE2IiqKhv1yB8N+Vnj8un8+m/pHocFn3rKI+E3xZ6vUnhge1Zh3ppT6AgcBBwOXNRj/LHBB/ZPCF+/ZwPNF01wGTAGmAv2AE4CZja2n6OfSxoqJiD0K89+66y9JDVwPXLyT8WOAZ1NKNc1dcMMgllK6vv49Bk4Dlha/70WTvjOl1K+w7m8D/w78dxOrexY4v2jdQ4AjgOXNrbsT+AHQF9gfGAC8i+3/ZttEGQb1GUAFcEjRsGOApQ2GHQvc9wbXVf/ZeghwGPDlhhNEpuy/m8vwfVQbKvsdVPlJKb0C3EkWIov9FXhzRAwqPD8VmAW8UjTNYcAtKaWlKbMwpXTtLpbyVuCJlNLm+gER8YWIeL7QgvJMRJxZGL4/8DPgyMJ/+Kt3stx9I+KfhUOzf4mIwUXLP6LQ+rU6Ip4qbsUqtDAuKKz7hULLWknrjYgPRXbIeF1hGTsMcIWWissKr29VoaWiZ4Np/i0iqiPi5Yj4UNHwt0fEzELryaKI+GqDxT8K7BMRYxpZ79eAy4H3FV7LRyKiS0R8OSJeLKzv2ogYUJi+vvXuIxHxElC5wy1egpTSmpTSbcD7gAsiYtJOJr++UGd9C9G5wC3A1qLX06Vof3k1Iv5U9F7Xh4HVhdd6ZNF8/1HY7i9ExGlFw0dExG0RsTIi5kfEx4rG9YqsdX5VRDxD9ndA0fh/j4glhfd/XkSc1PAFFfa9Vxq0ep0ZEbMKj6dGxIzCe7ssIr6/s+1Z5DDghpTSqpRSXUqpKqV0U2GZr2uBLW5dK+zzD0bEfxb+XqqKa4+IARHx34X9cElEfKO+/qJ5fxARK4GvF/6uJhXNPyyyVrnh0aAFb0fbrIn3lYj4YGF/fTUivrSjjZJS2gY8QhYOiYjhQHfgjw2GjeONh8f6dS4B7gAmFZZ/T0R8MyIeBDaS/W3ubD+riIgvxv99Bj4eEaML4yZExN2F+eZFxHuL5htSWObaiPgnsG/RuFL3gfr38auF4R+O7DNtVUTcGY18pqjjMTxqhyJiFFlL0fwGozYDtwHnFJ6fDzQMho8An42IT0TEgRERb6CUA4GG50A9T9Y6MAD4GvD7iNgjpTQX+DjwcKFla+BOlns+8GFgBFAD/BggIkYCfwe+AQwGPgf8T+ELrk9hutMKrWRHAU82Y73VwDuA/sCHgB9ExCE7mBbgA8ApZB/y49i+pWL3wusfCXwEuCb+L9BvKLy+gcDbgUsi4oz6GQstivOB7Q75FsZdAVwF/LHwWv4buLDwcwKwD1kLVsPTDI4ja9U6ZSevp2QppX8Ci8ne5x1ZCjwDnFx43ti++EngjEJ9I4BVwDWFcccWfg8svNaHC88PJ9vnhgLfBf67aB/+Q6GuEWSH968qClJXkL1X+5Jth+IW+vHApcBhhX3nFGBhI6/7EbL378Siwe8Hbig8/hHwo5RS/8J6/tT4pnmdR4BvRvYPzNgS5yl2OLCAbJtcAdxcFNZ+R/Y3tB/Z0YqTgY82Mu9w4ErgZrKgX++9wL0pperiFTaxzXb4vkbEROC/gA8Wxg0BRu3ktd3H/+0LxwIPFH6Kh72QUmqR81cLQe9tbH805oNkp5L0A15k5/vZZ8m239vIPks+DGwsfD7dTbavDC9M89OIOKAw3zVkn997FOb5cDNLL34fv1n4TPki8G5gGHB/oW51dCklf/x57Yfsg3k9sA5IwDSyL9b68b8lC1VHAw+ThZdlQC+yD9sLC9NVAP8CPAhsIfuSv6CR9awu+vnYDmr6JfDtJup+Eji98PhC4IEmpr+neJnARLLWqgqyw6XXNZj+TrIg0KdQ63uAXg2maXK9jdRxK/CpwuPjgcUNttHHi56/DXi+aNpNQNei8dXAETtYzw+BHzQY9iBw/g6m/yrw+6Ln04BPFD0fD2wDugJ7FfaVfUp4vdu9xgav9S2NDH8E+NJO3sOPAueRfWGNJzvUDtmX7vGFx3OBk4rm26OR2ou344XA/KLnvQvT7A6MBmqBfkXjvwX8tvB4AXBq0biL6l8vWbCqBt4CdGtiO30D+HXhcT+yMDmm8Pw+sn+YhjZzX+tF9kX/eOH1zyf7J4gdbId7gI8WbZOlQBSN/ydZ4NmN7G+8V9G4c4HpRfO+1KCWtwALGtsXi/eRnW2zJt7Xy4Ebi8b1Ifv7ft0+VrTOV4EgC+cfI/sHaVnRsN802DYb2f7zaz2N7NsN9vH6z7wXgZ/Wb7PC8q4smrap/Wwehc+7But4H3B/g2E/Jwv7FYXtM6Fo3FUUPrNK3Acavo93AB8pet6lsF3GNGff9Kf9/djyqMackbL/8o8HJpC1NGwnpfQA2X+aXwb+llLa1GB8bUrpmpTSm8lav74J/Dqyw7vF6xlY9PPLHdSziuwL9DURcX5EPFk4/LWa7PDP6+pswqKixy8C3QrLGAOcXb/swvKPBvZIKW0g+4D+OPByRPw9IiaUusKIOC0iHikcUlpNFgh3VnfDGkcUPX81bX9O4kayLzwi4vCImB4RyyNiTaHehuvpR/ZFVooRhfUX19KVLDg0VmtLGQmsbGKam8la6f4VuK6R8WOAW4rey7lkX8y7NTJtvddOwUgpbSw87Eu2HVamlNYVTftioU4K4xu+Z/XLmQ98miyYV0fEjRFR/H4WuwF4d2RXxL+b7LSN+mV9hKwVuioiHouId+zkdbwmpbQppXRVSulQspa4PwF/Lj7U24QlKWUJoei1jSDbvt3I/h7qt/HPyVqn6jXcNyqBXoX9dAzZqTG3NFLzzrbZzt7X7d6Hwt/tqzt5bY+Qvb+TyFoZ708prS8so35Yw0PWnyz+/CI7otCU+s+8MSmlTzT43CzeRk3tZ6Np/HzVMcDhDT67PkD2j88wsr/ZRvfPEjV8H8cAPypa10qysD3ydXOqQzE8aodSSveStTTu6Crn3wP/xusPEzZczqaU0jVkIXDiLpQyi+zLEoDCl80vyQ5nDSl8cD9N9qEF2X/PpRhd9HhPsv/KV5B9QF7XINj2SSl9u/B67kwpvZWspaOqUEuT6y0Egf8h2567Feq+vajuUmpcWuJru4Hs1ILRKaUBZOdjvraewnlN+wFPlbi8pWRfFMW11JC1zNQrdbuXJCIOI/sS2ukV7IVwdwdwCY2Hx0VkLWzF72fPlJ131tyalwKDI6L4n5k9gSWFxy/z+vesuNYbUkpHk23LBHxnB6/pGbIv9tPY/pA1KaXnUkrnkoWz7wA3FQ5XliyltJas1akPsDdZyyZkraz1dm8w28gGp5/U74+LyFoehxZt3/4ppQOKpt1uO6eU6sjC67mF1/e3BkGpeNodbbOdva/bvQ8R0ZssMO9oe2wGHiMLgHuklKoKo+4vDJtMC53vuBPF26ip/WwRRecrFllEdvi/eJv0TSldQnYRWQ073j9L2Qca/r0sAi5usL5eKaWHdvQi1TEYHtWUHwJvjYiGF81Adu7fW2nkQzUiPh3Zie+9IqJrRFxA1tLV8IrrUtwNHBL/d7FIH7IPseWFdX2IwonnBcuAURHRvYnlnhdZ/5G9yc7DuimlVEsWit8ZEacUTkzvWXgtoyLrI/FdhS/rLWSHoWpLXG93oEeh7prILsI4eQfT1vuXwnoHkx1y/GMT09frR9ZysTkippJ9QRebCiwsas1qyh+Az0TE3pF1L1J/TmSzr8ZuSkT0L7Sm3Uh26Hx2CbN9ETgupbSwkXE/Izs/a0xh+cMi4vTCuOVAHdl5nE1KKS0CHgK+VdgvJpO1BF5fmORPwGURMahwzvC/Fr2u8RFxYuGfiM1kpx3UsmM3kJ3XdyzwWl+bEXFeRAwrBLD6luOdLad+vq9ExGGRdaPVE/hUYf55KaXlZMHkvMI+/2FeH06GA5+MiG4RcTbZ+a23p5ReBu4Cvld477pExL4RcVwTJd1A1or/AYrCcYOad7bNdva+3gS8IyKOLvw9XknT33f3kbVyFgefBwrDXkkptdmV6SXsZ78iu/BobGQmR9bTwN+AcZFdLNSt8HNYROxf+Gy7GfhqRPSO7LzQC4rWWco+0NDPyPb3A+C1C6feUNdeah8Mj9qpwgfKtcBXGhm3MqU0rcGhrHqbgO+RHf5bQXb+43tSSguKpvlrbN/P4+sOWxXWs4zsMNfphefPFJb9MFlgO5DsnKl6lcAc4JWIWLGTl3cdWcvqK0BPsi/q+g/u08kCyXKy/64/T/b30oWstXUp2SGa44BPlLLeQsvKJ8kCxiqyQHfbTuqD7Ev1LrJz6RaQnQtXik8AV0bEOrLzvxpeVPEBsg/+Uv2abHvdB7xA9kX+rzudo/n+Wqh3EfAl4PtkFxU1KWVX9e+ohfJHZNv5rsLyHyE78b++1fKbwIOFQ29HlLC6c8nOD1tKdqj1ipTS3YVxXyNrMXyB7H0rbgntQdYF0QqyfW442T62I38gO3WkMqVUvD+dCsyJrI/MHwHnFFrOKPwd7egCowT8prD+pWT/+L29cHgWsvP8Pk92ePcAtg9RkF2hP7Yw/zeBs1JK9YeCzyf75+gZsn37JrKW+R1KKT1K1to1gqzluDE722Y7e1/nkH3m3EDWCrmK7DzYnbm3sPzi/eiBwrDWbnVszM72s++T/U3fBawl69KqV+Ez5mSyixmXkm2z75BtR8iO1vQtDP8t2f5QrKl9YDsppVsKy78xItaSHQE6bWfzqGOIxr/3pfJS+C/5d8DUHYTVDiciFpKdrP6PFl7ucLIvyoNTUfdH0o5E1vn/RwuHjyV1cnbyqXah0Np4WJMTqkkp6w5l/yYnlCSpER62liRJUsk8bC1JkqSS2fIoSZKkkhkeJUmSVLIOecHM0KFD01577ZV3GZIkSU16/PHHV6SUhuVdR6k6ZHjca6+9mDFjRt5lSJIkNSkimnuryFx52FqSJEklMzxKkiSpZIZHSZIklczwKEmSpJIZHiVJklQyw6MkSZJKZniUJElSyQyPkiRJKpnhUZIkSSUzPEqSJKlkhkdJkqQd+MxnPsMPf/jD156fcsopfPSjH33t+b/9279x1VVXcdZZZzU6//HHH9/qt0yOiPUNnl8YET9pYp5hEfFoRMyMiGMi4uyImBsR05tan+FRkiRpB4466igeeughAOrq6lixYgVz5sx5bfxDDz3ESSedxE033dSs5dbW1rZonbvgJKAqpXRwSul+4CPAJ1JKJzQ1o+FRkiRpB9785je/Fh7nzJnDpEmT6NevH6tWrWLLli3MnTuXQYMGMWnSJAA2bdrEOeecw+TJk3nf+97Hpk2bXltW3759ufzyyzn88MN5+OGHmTZtGgcffDDAxIj4dUT0iIipEXEzQEScHhGbIqJ7RPSMiAXNrT8ixkTEtIiYVfi9Z0QcBHwXeFtEPBkRVwBHAz+LiKubWmbX5hYhSZLUWYwYMYKuXbvy0ksv8dBDD3HkkUeyZMkSHn74YQYMGMDkyZPp3r37a9P/13/9F71792bWrFnMmjWLQw455LVxGzZsYNKkSVx55ZVs3ryZsWPHMm3aNMaPH/8MWSa7BPgJcHBhlmOAp4HDCuMf3UGZvSLiyaLng4HbCo9/AlybUvpdRHwY+HFK6YyIuByYklK6FCAiTgA+l1Jq8hi7LY+SJEk7Ud/6WB8ejzzyyNeeH3XUUdtNe99993HeeecBMHnyZCZPnvzauIqKCt7znvcAMG/ePPbee2/GjRtXP/p3wLEppRpgfkTsD0wFvg8cSxYk799BiZtSSgfV/wCXF407Erih8Pg6shbGN8SWR0mSpAZunbmEq++cx9LVm4j1Q1jzl7tYOm82kyZNYvTo0Xzve9+jf//+fPjDH37dvBHR6DJ79uxJRUUFACmlna3+fuA0YBvwD+C3QAXwuYgYDfy1MN3PUko/a+ZL2+mKS2HLoyRJUpFbZy7hsptns2T1JhKwefBY7vrfO6jt1oeKigoGDx7M6tWrefjhhznyyCO3m/fYY4/l+uuvB+Dpp59m1qxZja5jwoQJLFy4kPnz59cP+iBwb+HxfcCngYdTSsuBIcAEYE5KaVFRK2MpwfEh4JzC4w8AD5S4GXbI8ChJklTk6jvnsWnb/10N3W3YGGo2rmFlnzGvDTvwwAMZMGAAQ4cO3W7eSy65hPXr1zN58mS++93vMnXq1EbX0bNnT37zm99w9tlnA0wE6oD6MPgosBtZiASYBcxKTTRX7sAngQ9FxCyygPqpXVjGdmLX6ihvU6ZMSa3dp5IkSeqY9v7C3xs9thvAC99+e4uvLyIeTylNafEFtxJbHiVJkoqMGNirWcM7G8OjJElSkc+fMp6uXba/6KVXtwo+f8r4nCoqL4ZHSZKkImccPJKhfbvTvWsXAhg5sBffeveBnHHwyLxLKwt21SNJklRk0cqNvLJ2C1962/587Nh98i6n7NjyKEmSVGT6vGoATtx/eM6VlCfDoyRJUpHKqmr2GtKbfYb2ybuUsmR4lCRJKti4tYaHnn+VEyYM3+GdYjo7w6MkSVLBQ/NfZWtNHSdN2C3vUsqW4VGSJKlgWlU1fbpXMHXvwXmXUrYMj5IkSUBKielV1RwzdhjduxqRdqTNtkxEnBoR8yJifkR8oZHxx0bEExFRExFnNRj33YiYExFzI+LH4UkIkiSphT3z8lpeWbvZq6yb0CbhMSIqgGuA08hu/n1uRExsMNlLwIXADQ3mPQp4MzAZmAQcBhzXyiVLkqROpnJu1kXP8eOH5VxJeWurTsKnAvNTSgsAIuJG4HTgmfoJUkoLC+PqGsybgJ5Ad7J7kncDlrV+yZIkqTOpnFfNm0YNYHi/nnmXUtba6rD1SGBR0fPFhWFNSik9DEwHXi783JlSmtviFUqSpE5rxfotPLloNSdM8JB1U9oqPDZ2jmIqacaI/YD9gVFkgfPEiDi2kekuiogZETFj+fLlb6hYSZLUudwzbzkpYRc9JWir8LgYGF30fBSwtMR5zwQeSSmtTymtB+4Ajmg4UUrpFymlKSmlKcOGea6CJEkq3fSqaob368EBI/rnXUrZa6vw+BgwNiL2jojuwDnAbSXO+xJwXER0jYhuZBfLeNhakiS1iG21ddz37HJOGD+cLl3s0KUpbRIeU0o1wKXAnWTB708ppTkRcWVEvAsgIg6LiMXA2cDPI2JOYfabgOeB2cBTwFMppb+2Rd2SJKnje2zhStZtqbGLnhK11dXWpJRuB25vMOzyosePkR3ObjhfLXBxqxcoSZI6pcq51XSv6MLR+w3Nu5R2we7TJUlSp1ZZVc3h+wymT482a1Nr1wyPkiSp03phxQYWrNjASXbRUzLDoyRJ6rQqq7K7ypxoFz0lMzxKkqROa3pVNfsN78ueQ3rnXUq7YXiUJEmd0votNTz6wquc6CHrZjE8SpKkTumB55azrTYZHpvJ8ChJkjqlaXOr6d+zK4eOGZR3Ke2K4VGSJHU6dXWJ6fOqOXbcMLpVGIeaw60lSZI6ndlL1rBi/VZO8q4yzWZ4lCRJnc60qmoi4LhxhsfmMjxKkqROZ3pVNYfsOYjBfbrnXUq7Y3iUJEmdyrK1m5m9ZI1XWe8iw6MkSepUpr92VxnD464wPEqSpE6lsqqaEQN6MmH3fnmX0i4ZHiVJUqexpaaWB+av4IQJw4mIvMtplwyPkiSp03h0wUo2bq21i543wPAoSZI6jcqqanp268JR+w7Nu5R2y/AoSZI6hZQS06qWcdS+Q+nZrSLvctotw6MkSeoUnl++nkUrN3mV9RtkeJQkSZ3CtLlZFz0nGB7fEMOjJEnqFCqrqpmwez9GDuyVdyntmuFRkiR1eGs2bmPGi6u8yroFGB4lSVKHd+9zy6mtS57v2AIMj5IkqcObXlXNoN7dOGj0oLxLafcMj5IkqUOrrUvcM6+a48cPp6KLd5V5owyPkiSpQ3ty0SpWbdzmIesWYniUJEkd2rS51VR0CY4dNyzvUjoEw6MkSerQKquqmTJmEAN6dcu7lA7B8ChJkjqsJas3UfXKOrvoaUGGR0mS1GFVVmV3lfF8x5ZjeJQkSR3W9Kpq9hzcm32H9c27lA7D8ChJkjqkTVtreXD+Ck6cMJwIu+hpKYZHSZLUIT28YAVbauo8ZN3CDI+SJKlDmja3mt7dKzh8n8F5l9KhGB4lSVKHk1Kisqqao/cbSo+uFXmX06EYHiVJUodT9co6Xl6z2S56WoHhUZIkdTj1XfScMN7w2NIMj5IkqcOprKrmwJEDGN6/Z96ldDiGR0mS1KGs3LCVJ15a5VXWrcTwKEmSOpR75lWTkneVaS2GR0mS1KFUVlUztG8PDhw5IO9SOiTDoyRJ6jC21dZx77PLOWH8MLp08a4yrcHwKEmSOozHX1zFus01dtHTigyPkiSpw6isqqZbRXD02GF5l9JhGR4lSVKHUVlVzeF7D6Fvj655l9JhGR4lSVKH8OKrG5hfvd6rrFuZ4VGSJHUI9XeVMTy2LsOjJEnqECqrqtlnWB/2Gton71I6NMOjJElq9zZsqeHRBSs5yVbHVmd4lCRJ7d4D81ewtbaOEwyPrc7wKEmS2r3KudX069GVw/YanHcpHZ7hUZIktWt1dYnKedUcO24Y3SqMNq3NLSxJktq1OUvXsnzdFq+ybiOGR0mS1K5Nq1pGBBw/3rvKtAXDoyRJatemV1Vz0OiBDOnbI+9SOgXDoyRJareq123mqcVr7KKnDRkeJUlSu3VP1XIAu+hpQ4ZHSZLUblVWVbN7/55M3KN/3qV0GoZHSZLULm2pqeX+55Zz4v7DiYi8y+k0DI+SJKldeuyFVWzYWsuJ4z1k3ZYMj5IkqV2aVrWMHl278Ob9huZdSqdieJQkSe1OSonKqmqO3HcIvbpX5F1Op2J4lCRJ7c6CFRt48dWNdtGTA8OjJElqdyrnVgN20ZMHw6MkSWp3KquqGb9bP0YN6p13KZ2O4VGSJLUrazdv47GFKzlxf1sd82B4lCRJ7cr9z66gpi5xooesc2F4lCRJ7cq0qmUM7N2Ng0cPzLuUTqnNwmNEnBoR8yJifkR8oZHxx0bEExFRExFnNRi3Z0TcFRFzI+KZiNirreqWJEnlo7Yucc+85Rw/bhhdK2wDy0ObbPWIqACuAU4DJgLnRsTEBpO9BFwI3NDIIq4Frk4p7Q9MBapbr1pJklSunlq8mpUbtnqVdY66ttF6pgLzU0oLACLiRuB04Jn6CVJKCwvj6opnLITMrimluwvTrW+jmiVJUpmpnFtNRZfguHHD8i6l02qr9t6RwKKi54sLw0oxDlgdETdHxMyIuLrQkilJkjqZyqpqDt1zEAN7d8+7lE6rrcJjNDIslThvV+AY4HPAYcA+ZIe3t19BxEURMSMiZixfvnxX65QkSWXq5TWbeObltXbRk7O2Co+LgdFFz0cBS5sx78yU0oKUUg1wK3BIw4lSSr9IKU1JKU0ZNsymbEmSOprKquySB29JmK+2Co+PAWMjYu+I6A6cA9zWjHkHRUR9IjyRonMlJUlS5zC9qppRg3qx3/C+eZfSqbVJeCy0GF4K3AnMBf6UUpoTEVdGxLsAIuKwiFgMnA38PCLmFOatJTtkPS0iZpMdAv9lW9QtSZLKw+ZttTwwfwUnTRhORGNnw6mttNXV1qSUbgdubzDs8qLHj5Edzm5s3ruBya1aoCRJKlsPL3iVzdvq7KKnDNi7piRJKnuVc6vp1a2CI/YZkncpnZ7hUZIklbWUEpVV1Rw9dig9u9lbX94Mj5Ikqaw9u2w9S1Zv4kQPWZcFw6MkSSpr06qWAXDCeMNjOTA8SpKksja9qpoDRvRn9wE98y5FGB4lSVIZW7VhK4+/uMqOwcuI4VGSJJWte59dTl3CLnrKiOFRkiSVrcqqaob06c6bRg3MuxQVGB4lSVJZqqmt45551ZwwYThdunhXmXJheJQkSWXpiZdWs3ZzjV30lBnDoyRJKkvTqpbRtUtwzNiheZeiIoZHSZJUlqZXVTN178H069kt71JUxPAoSZLKzqKVG3l22XoPWZchw6MkSSo7lVXVAJy0/245V6KGDI+SJKnsVFZVs/fQPuw9tE/epagBw6MkSSorG7fW8PCCVz1kXaYMj5Ikqaw8OP9VttbUGR7LlOFRkiSVlcqqZfTt0ZXD9hqcdylqhOFRkiSVjZQSlVXVHDtuKN27GlPKke+KJEkqG3OWrmXZ2i2cMN5D1uXK8ChJkspGZVU1EXC84bFsGR4lSVLZqKyqZvKogQzr1yPvUrQDhkdJklQWlq/bwlOLV3OSV1mXNcOjJEkqC/fMqyYl7KKnzBkeJUlSWZg+r5rd+vfggBH98y5FO2F4lCRJudtaU8d9z67gxAnDiYi8y9FOGB4lSVLuZixcyfotNXbR0w4YHiVJUu6mVVXTvWsX3rzf0LxLURMMj5IkKXeVVdUcuc8Q+vTomncpaoLhUZIk5WEXJj8AACAASURBVGrB8vW8sGKDV1m3E4ZHSZKUq8qqasAuetoLw6MkScrV9HnVjB3el9GDe+ddikpgeJQkSblZt3kbjy5YyYn72+rYXhgeJUlSbh54bgU1dYmTJuyWdykqkeFRkiTlZlpVNQN6deOQPQfmXYpKZHiUJEm5qKtL3DOvmuPGDaNrhZGkvfCdkiRJuZi1ZA0r1m/1Kut2xvAoSZJyUTl3GV0Cjhs3LO9S1AyGR0mSlIvKedUcOmYQg/p0z7sUNYPhUZIktblX1mzm6SVrOcFD1u2O4VGSJLW56fOyu8rYRU/7Y3iUJEltrrKqmpEDezFut755l6JmMjxKkqQ2tXlbLQ88t4ITJwwnIvIuR81keJQkSW3q0RdWsmlbrbckbKcMj5IkqU1Vzl1Gz25dOHKfIXmXol1geJQkSW0mpcS0qmqO3m8oPbtV5F2OdoHhUZIktZn51etZvGqTXfS0Y4ZHSZLUZqZVZV30eEvC9svwKEmS2kxlVTUT9+jPHgN65V2KdpHhUZIktYnVG7fy+IurbHVs5wyPkiSpTdz77HJq65Jd9LRzhkdJktQmpldVM7hPd940amDepegNMDxKkqRWV1uXuOfZ5Rw/fhgVXbyrTHtmeJQkSa1u5kurWL1xm+c7dgCGR0mS1OqmVVXTtUtwzNhheZeiN8jwKEmSWt30qmoO22swA3p1y7sUvUGGR0mS1KoWr9pI1SvrPGTdQRgeJUlSq5pef1cZu+jpEAyPkiSpVVVWVTNmSG/2Gdon71LUAgyPkiSp1WzaWstDz7/KiROGE2EXPR1Bs8NjRPSJiIrWKEaSJHUsDz2/gi01dZw0Ybe8S1ELaTI8RkSXiHh/RPw9IqqBKuDliJgTEVdHxNjWL1OSJLVH06qq6dO9gql7D867FLWQUloepwP7ApcBu6eURqeUhgPHAI8A346I81qxRkmS1A6llJheVc0xY4fRvatnynUUXUuY5i0ppW0RcWhKqa5+YEppJfA/wP9EhJ02SZKk7cx9eR0vr9nMZ97iVdYdSZP/BqSUthUeXhARN0XEEfXjIuL7DaaRJEkCoLJqGQDHT/CuMh1Jc9qQq4EpwM0RMS8iXgB2b52yJElSe1dZVc2bRg1geL+eeZeiFtSc8HgeMD6lNAI4AbgP+GerVCVJktq1V9dvYeai1ZzgXWU6nOaEx0XA3gAppaUppQuAi1ulKkmS1K7dM285KWEXPR1Qc8Ljp8gujrkuIj4TEd8DNpQ6c0ScWjjcPT8ivtDI+GMj4omIqImIsxoZ3z8ilkTET5pRsyRJykHlvGqG9evBASP6512KWljJ4TGl9AxwCHAj0Ad4BTi9lHkLnYpfA5wGTATOjYiJDSZ7CbgQuGEHi/k6cG+p9UqSpHxsq63jvnnLOXH8cLp08a4yHU0pXfW8JqW0Bfh74ac5pgLzU0oLACLiRrLg+UzRshcWxtU1nDkiDgV2A/6X7KIdSZJUpmYsXMW6LTWcuL/nO3ZEbdVj50iycybrLS4Ma1JEdAG+B3y+FeqSJEktrLJqGd0runD0fkPzLkWtoK3CY2Nt1qnEeT8B3J5SWrSziSLiooiYEREzli9f3uwCJUlSy5hWVc3h+wymT49mHeBUO1FyeIyI75QybAcWA6OLno8ClpY475HApRGxEPgP4PyI+HbDiVJKv0gpTUkpTRk2zM5IJUlqa7fOXMLhV/2DBcs3MGvxam6duSTvktQKmtPy+NZGhp1W4ryPAWMjYu+I6A6cA9xWyowppQ+klPZMKe0FfA64NqX0uqu1JUlSfm6duYTLbp7NsrVbAFizqYbLbp5tgOyAmgyPEXFJRMwGJkTErKKfF4DZpawkpVQDXArcCcwF/pRSmhMRV0bEuwrrOSwiFgNnAz+PiDm7+qIkSVLbuvrOeWzaVrvdsE3barn6znk5VaTWUsrJCDcAdwDfAopb/NallFaWuqKU0u3A7Q2GXV70+DGyw9k7W8Zvgd+Wuk5JktQ2lq7e1Kzhar+abHlMKa0pdKNzM7AypfQi8EHgVxFxcCvXJ0mS2oE9BjZ+/+oRA3u1cSVqbc055/ErKaV1EXE0cArwO+BnrVOWJElqT6aMGfS6Yb26VfD5U8bnUI1aU3PCY/2JDG8H/iul9Bege8uXJEmS2pMlqzdx9zPVHDCiHyMH9iSAkQN78a13H8gZB5fUrbPakeZ0wLQkIn4OvAX4TkT0oO36iZQkSWXqq7dl17j+/INTGDWod87VqLU1J/y9l+xq6VNTSquBwXjXF0mSOrW75rzC3c8s49NvGWtw7CRKbnlMKW0ku2im/vnLwMutUZQkSSp/G7bU8NXb5jB+t358+Oi98y5HbaQ5d5iJiDgvIi4vPN8zIqa2XmmSJKmc/Wjacyxds5lvnjmJbhWeydZZNOed/inZrQLPLTxfB1zT4hVJkqSyN/fltfz3Ay9wzmGjmbLX4LzLURtqzgUzh6eUDomImQAppVWFWw1KkqROpK4u8aVbZjOgVze+cNqEvMtRG2tOy+O2iKgAEkBEDAPqWqUqSZJUtv44YxFPvLSaL71tfwb2th2ps2lOePwxcAuwW0R8E3gAuKpVqpIkSWVpxfotfPuOKg7fezDvPsQ+HDuj5lxtfX1EPA6cVBh0RkppbuuUJUmSytFVf5/Lxq01fPPMSURE3uUoByWHx4joCbwNOIbscHX3iHghpbS5tYqTJEnl46HnV3DzzCVcesJ+7De8X97lKCfNuWDmWrIrrH9ceH4ucB1wdksXJUmSysuWmlq+fOvT7Dm4N5eeuF/e5ShHzQmP41NKbyp6Pj0inmrpgiRJUvn5xb0LWLB8A7/90GH07FaRdznKUXMumJkZEUfUP4mIw4EHW74kSZJUThau2MB/Tp/P2yfvwfHjh+ddjnLWZMtjRMwm656nG3B+RLxUeD4GeKZ1y5MkSXlKKfGVvzxN94ouXP6OiXmXozJQymHrd7R6FZIkqSz9bdbL3P/cCr76zons1r9n3uWoDDQZHlNKL7ZFIZIkqbys3byNK//2DAeOHMAHj9wr73JUJppzwYwkSepEvnfnPF5dv4VfX3AYFV3s01GZ5lwwI0mSOomnFq3m2kde5Pwj9+LAUQPyLkdlpOTwGBHfKWWYJElq32pq6/jiLbMZ1rcHnz15XN7lqMw0p+XxrY0MO62lCpEkSeXhukdeZM7StVz+zon079kt73JUZkrpqucS4BPAPhExq2hUP+Ch1ipMkiS1vVfWbOZ7dz3LceOG8fYD98i7HJWhUi6YuQG4A/gW8IWi4etSSitbpSpJkpSLr//tGbbV1nHl6QcQ4UUyer1SuupZA6wBzo2IQcBYoCdARJBSuq91S5QkSW1h+rxq/j77ZT538jjGDOmTdzkqUyV31RMRHwU+BYwCngSOAB4GTmyd0iRJUlvZtLWWy//yNPsO68PHjt0n73JUxppzwcyngMOAF1NKJwAHA8tbpSpJktSmfjL9ORat3MQ3zjiQHl0r8i5HZaw54XFzSmkzQET0SClVAeNbpyxJktRWnlu2jl/ct4D3HDKKI/cdknc5KnPNucPM4ogYCNwK3B0Rq4ClrVOWJElqCyklvnTr0/Tu3pUvvm1C3uWoHSg5PKaUziw8/GpETAcGAP/bKlVJkqQ2cdPji/nnCyv59rsPZEjfHnmXo3aglH4eI6WUioellO5tahpJklTeVm3YylW3z+XQMYN475TReZejdqKUcx6nR8S/RsSexQMjontEnBgRvwMuaJ3yJElSa/n2HVWs21zDN8+cRJcu9umo0pRy2PpU4MPAHyJib2A1WT+PFcBdwA9SSk+2XomSJKmlPbZwJX+csYiLj9uHCbv3z7sctSOldBK+Gfgp8NOI6AYMBTallFa3dnGSJKnlbaut40u3zGbkwF586qSxeZejdqY5V1uTUtoGvNxKtUiSpDbwq/tf4Nll6/nV+VPo3b1ZUUBqVj+PkiSpnVu0ciM/mvYsJ0/cjbdM3C3vctQOGR4lSeokUkpccdscukTw1XcdkHc5aqeaDI8R4d4lSVIHcOecZVRWVfPZt45jxMBeeZejdqqUlsfr6h9ExEeLR0RE7xavSJIktbj1W2r46m1z2H+P/lx41F55l6N2rJTwWNzx0ycajLu/BWuRJEmt5Ad3P8uydZv55pmT6FrhWWvadaXsPcV3jmnYg6h7nyRJZe7pJWv4zYMvcO7UPTlkz0F5l6N2rpTr83ePiAuBp3h9ePSWhJIklbHausSXbn2awX268++nTMi7HHUApYTHrwFTgA8BoyJiDlBV+BnairVJkqQ36A//fImnFq3mh+87iAG9u+VdjjqAUu4w8/Pi5xExCpgMHAjc10p1SZKkN6h63Wa+879VHLXvEE4/aETe5aiDKKWrnmkNuus5pPBzT0rpvFarTJIkvSHf/Ptctmyr4+tnTCKi4Zln0q4p5YKXUSmlOQARcRRZ1z17Ar+OiDNbszhJkrRrHnhuBX95cikfP35f9h3WN+9y1IGUEh7XFj0+H/hZSuki4ATg31ulKkmStMs2b6vlK395mr2G9OYTx++bdznqYEoJj/Mj4qyIGA6cAfwFIKVUDfRozeIkSVLz/eze53lhxQa+fsYkenaryLscdTClhMfPABcDS4AnUkoPAUREN8B2cEmSysiC5ev56fTnedebRnDM2GF5l6MOqJSrrV8B3hoRXVJKdUWjTgCmt1plkiSpWVJKfOUvT9OjWxe+/I798y5HHVQpV1ufGBHDGgRHUkp3Fc59lCRJZeC2p5by4PxX+X+njGd4v555l6MOqpROwv8BVEdEHfA0MAuYXfj9TEppSyvWJ0mSSrBm4za+/rdneNOoAbz/8DF5l6MOrJTw+Engw8CfgIeA8cChwIXA/sDurVWcJEkqzdV3VbFyw1Z++6GpVHSxT0e1niYPW6eUfgK8mew+1j8EtgGfSimdkFIyOEqSlLOZL63i+kdf4sKj9mbSyAF5l6MOrpSrrUkpbUopfQc4HtgP+GdEHN6ahUmSpKbV1NbxxVueZrd+PfnsyePyLkedQJOHrSPiGLLD0xMKv4cD64AhrVuaJElqym8fWsjcl9fyXx84hL49SjkbTXpjStnL7gWeAv4A/DiltLBVK5IkSSVZunoT37/7WU4YP4xTJ3kmmdpGKeHxEuBA4O3A5yJiBdnV1rOBp1NKt7ZifZIkaQe+9tc51KXEladPIsKLZNQ2Sukk/OfFzyNiFDCZLFC+BzA8SpLUxv7xzDLunLOM/3fqeEYP7p13OepESukk/LyIWB4RiyPi/JTSYmAl0A+Y2OoVSpKk7WzcWsMVt81h7PC+fPToffIuR51MKVdbXwG8DTgY2Cci7gb+DHQDPt2KtUmSpEb8eNp8lqzexDfOmET3riV1nCK1mFLOeVyfUnoMICK+BiwDxqWUVrdqZZIk6XXmvbKOX92/gLMPHcXh+9jxidpeKeFx94i4CJhX+FlscJQkqe3V1SW+dMts+vXsymVv2z/vctRJlRIeryC7QOYDZBfJ9IuIfwAzgZkppRtasT5JklTw58cXMePFVXz3rMkM7tM973LUSZVytfUvip83uNr6NMDwKElSK3t1/Ra+dUcVU/cazFmHjMq7HHVize6KvnC19WLg9pYvR5IkNeZbd1SxfnMN3zhzEl262Kej8uMlWpIklblHFrzKTY8v5mPH7sO43frlXY46uTYLjxFxakTMi4j5EfGFRsYfGxFPRERNRJxVNPygiHg4IuZExKyIeF9b1SxJUt621tTx5VufZtSgXnzyxLF5lyO1TXiMiArgGrJzJCcC50ZEww7GXwIu5PXnUG4Ezk8pHQCcCvwwIga2bsWSJJWHX96/gPnV6/n66ZPo1b0i73Kk5p/zuIumAvNTSgsAIuJG4HTgmfoJUkoLC+PqimdMKT1b9HhpRFQDwwC7C5IkdWgvvbqRH097jtMm7c4JE4bnXY4EtN1h65HAoqLniwvDmiUipgLdgedbqC5JkspSSomv/OVpunYJLn+ndwNW+Wir8NjYZWGpWQuI2AO4DvhQSqmukfEXRcSMiJixfPnyXSxTkqTycMfTr3Dvs8v57Mnj2WNAr7zLkV7TVuFxMTC66PkoYGmpM0dEf+DvwJdTSo80Nk1K6RcppSkppSnDhg17Q8VKkpSndZu38bW/zuGAEf254MgxeZcjbaetwuNjwNiI2DsiugPnALeVMmNh+luAa1NKf27FGiVJKgvfu+tZqtdt4ZtnHkjXCnvVU3lpkz0ypVQDXArcCcwF/pRSmhMRV0bEuwAi4rCIWAycDfw8IuYUZn8vcCxwYUQ8Wfg5qC3qliSprc1evIZrH17IeYeP4aDRdi6i8hMpNevUw3ZhypQpacaMGXmXIUlSs9TWJc786YMsXb2Zaf92HAN6dcu7JLWBiHg8pTQl7zpKZVu4JEll4vpHX2TW4jV85R37GxxVtgyPkiSVgWVrN3P1/87jmLFDedebRuRdjrRDbdVJuCRJasStM5dw9Z3zWLJ6EwDHjh1GRGM93EnlwZZHSZJycuvMJVx28+zXgiPA9+9+lltnLsmxKmnnDI+SJOXk6jvnsWlb7XbDNm2r5eo75+VUkdQ0w6MkSTlZWtTiWMpwqRwYHiVJykm/no1fejBioLcjVPkyPEqSlIPKqmWs3VxDRYOLY3p1q+Dzp4zPqSqpaYZHSZLa2PPL1/OpPzzJxD368613H8jIgb0IYOTAXnzr3QdyxsEj8y5R2iG76pEkqQ2t3byNj107g25du/CL8w9l1KDevPew0XmXJZXM8ChJUhupq0t89o9P8uKrG/n9Rw5n1KDeeZckNZuHrSVJaiM/+Mez/GNuNZe/YyJH7jsk73KkXWJ4lCSpDdwx+2X+s3I+750yivOPHJN3OdIuMzxKktTKql5Zy7/9+SkO3nMgXz9jkrcfVLtmeJQkqRWt2rCVj107g749uvKz8w6lR9eKvEuS3hAvmJEkqZXU1Nbxr3+YybI1W7jx4iPYrX/PvEuS3jDDoyRJreTbd1TxwPwVfPc9kzlkz0F5lyO1CA9bS5LUCm5+YjG/euAFLjhyjP04qkMxPEqS1MJmLV7NF26ezRH7DObL75iYdzlSizI8SpLUgpav28LF1z3OsL49uOb9h9Ctwq9adSye8yhJUgvZWlPHJb9/nFUbt3LTx49iSN8eeZcktTjDoyRJLeRrf53DjBdX8aNzDmLSyAF5lyO1CtvSJUlqATc8+hLXP/oSFx+3D6cfNDLvcqRWY3iUJOkNmrFwJVfc9jTHjRvG/ztlQt7lSK3K8ChJ0hvw8ppNfPz3TzByYC9+fM7BVHTx1oPq2DznUZKkXbR5Wy0XX/c4m7bW8IePHc6A3t3yLklqdYZHSZJ2QUqJL94ym1mL1/CLDx7K2N365V2S1CY8bC1J0i749YMLufmJJXzmLeM4+YDd8y5HajOGR0mSmunB+Su46va5nDxxN/71xP3yLkdqU4ZHSZKa4aVXN/IvNzzBvsP68P33HUQXL5BRJ2N4lCSpRBu21HDRdTOoq0v84oNT6NvDSwfU+bjXS5JUgpQSn7/pKZ5dto7ffmgqew3tk3dJUi5seZQkqQQ/ved5bp/9Cl84bQLHjhuWdzlSbgyPkiQ1obJqGf9x1zzOOGgEHztmn7zLkXJleJQkaSfmV6/nU394kgNG9Ofb75lMhBfIqHMzPEqStANrN2/joutm0L1rF37+wSn07FaRd0lS7rxgRpKkRtTWJT5945O89OpGrv/o4Ywc2CvvkqSyYMujJEmN+P7d86isquaKd07k8H2G5F2OVDYMj5IkNfD3WS9zzfTnOeew0Zx3xJi8y5HKiuFRkqQic19ey+f+/BSH7DmQr51+gBfISA0YHiVJKli1YSsXXTeD/r268rPzDqVHVy+QkRryghlJkoCa2jr+5YYnWLZmC3+8+AiG9++Zd0lSWTI8SpIEXHV7FQ89/ypXnzWZg/cclHc5UtnysLUkqdP7n8cX8+sHX+DCo/bi7Cmj8y5HKmuGR0lSp/bUotVcdstsjtxnCF96+/55lyOVPcOjJKnTql63mYuve5zh/XpwzQcOoVuFX4tSUzznUZLUKW2tqeMTv3+CNZu28T+XHMXgPt3zLklqFwyPkqRO6Yrb5jDjxVX85P0HM3FE/7zLkdoN2+clSZ3O7x95kT/88yUuOX5f3jF5RN7lSO2K4VGS1Kn884WVfPW2ORw/fhifO3l83uVI7Y7hUZLUaSxdvYlPXP84ew7uzY/OOZiKLt56UGouz3mUJHUKm7fVcvF1j7N5Wx03XnQoA3p1y7skqV0yPEqSOryUEpfdPJunl67hlx+cwn7D++VdktRuedhaktTh/fcDL3DLzCV89i3jeMvE3fIuR2rXDI+SpA7t/ueWc9Xtczlt0u5ceuJ+eZcjtXuGR0lSh/XSqxu59IaZjB3ej/84+01EeIGM9EYZHiVJHdKGLTV87NoZAPzi/EPp08PT/KWWYHiUJHU4KSU+9+eneK56Hde8/xDGDOmTd0lSh2F4lCR1OD+pnM8dT7/CF9+2P0ePHZp3OVKHYniUJHUo/3hmGd+7+1nOPHgkHzl677zLkTocw6MkqcOYX72OT//xSQ4cOYBvvftAL5CRWoHhUZLUIazZtI2PXfs4Pbt14ecfPJSe3SryLknqkLz0TJLU7tXWJT5940wWrdzIDR87ghEDe+VdktRhGR4lSe3e9+6ax/R5y/nGGZOYuvfgvMuROjQPW0uS2rW/zVrKT+95nnOn7sl5R4zJuxypwzM8SpLarWeWruXzf57FlDGD+Nq7Dsi7HKlT8LC1JKlduXXmEq6+cx5LV2+iSwR9elTw0/MOoXtX20OktuBfmiSp3bh15hIuu3k2S1ZvIgG1KbGlpo6H5r+ad2lSp9Fm4TEiTo2IeRExPyK+0Mj4YyPiiYioiYizGoy7ICKeK/xc0FY1S5LKy9V3zmPTttrthm2pqePqO+flVJHU+bRJeIyICuAa4DRgInBuRExsMNlLwIXADQ3mHQxcARwOTAWuiIhBrV2zJKm8bNpay5LVmxodt3QHwyW1vLZqeZwKzE8pLUgpbQVuBE4vniCltDClNAuoazDvKcDdKaWVKaVVwN3AqW1RtCSpPNz77HJO/uG9Oxxvv45S22mr8DgSWFT0fHFhWGvPK0lqx1as38Knb5zJBb/+J926dOHSE/alV4M7x/TqVsHnTxmfU4VS59NWV1s3dnPR1JLzRsRFwEUAe+65Z+mVSZLKTkqJPz++mKtun8uGLTV88qSxfOL4fenZrYL9hvd77WrrEQN78flTxnPGwbYpSG2lrcLjYmB00fNRwNJmzHt8g3nvaThRSukXwC8ApkyZUmowlSSVmQXL1/PFW2bzyIKVHLbXIK4680DG7tbvtfFnHDzSsCjlqK3C42PA2IjYG1gCnAO8v8R57wSuKrpI5mTgspYvUZKUp601dfz83uf5z+nz6dG1C99694G8b8pounRp7ACUpLy0SXhMKdVExKVkQbAC+HVKaU5EXAnMSCndFhGHAbcAg4B3RsTXUkoHpJRWRsTXyQIowJUppZVtUbckqW3MWLiSy26ezXPV63n75D244h0TGd6/Z95lSWpEpNTxjvBOmTIlzZgxI+8yJElNWLNpG9/93yquf/QlRg7sxdfPOIATJ+yWd1lSm4qIx1NKU/Kuo1TenlCS1OZSStzx9CtccdscXl2/hY8cvTeffes4+vTwa0kqd/6VSpLa1JLVm7j81qeZVlXNASP68+sLDuPAUQPyLktSiQyPkqQ2UVuX+N1DC/mPu+aREnzpbfvzoTfvRdeKNrtTrqQWYHiUJLW6p5es4Yu3zGbW4jUcP34YXz99EqMH9867LEm7wPAoSWo1G7fW8KN/PMevHniBQb278Z/nHsw7Ju9BhN3vSO2V4VGS1CrumVfNl299msWrNnHu1NF84dT9GdC7W95lSXqDDI+SpBa1fN0Wvv63Z7jtqaXsO6wPf7r4SKbuPTjvsiS1EMOjJKlFpJT404xFXHV7FZu21vLpt4zlkuP3pUfXirxLk9SCDI+SpDfs+eXr+eLNs3n0hZVM3WswV737QPYb3jfvsiS1AsOjJGmXbamp5Wf3LOCa6fPp2a0L3373gbzX+1FLHZrhUZK0Sx4r3I96fvV63vmmEXzlHfszvJ/3o5Y6OsOjJKlZ1mzaxrfvqOIP/8zuR/2bDx3GCeOH512WpDZieJQklSSlxO2zX+Gr/7+9Ow+Ou7zvOP7+6ljdlqzTtowvHbYBE2zEVVIbCARDJhgoSQiTJnSYJE0maUtSp5DShiEzCYFp0nRKDxpy0E6bEmI7hiTQTCA4lxMcC7ABS5aNAUlYt2Tdu9p9+sdvLa112D8Ze3el/bxmNNpdPZK+8uNdffRcvye961F//I9Xcte1teQG9KtEJJXoGS8iIqfU3DPE3//oFZ490M66ykK+c8fFnF+p61GLpCKFRxERmdFYOMJ3f3OEr/+sEYB737eWO/5I16MWSWUKjyIiMq39LX3cs20f+1r6uHpNOfdvOY+lC3U9apFUp/AoIiInGAqO8Y2fNfLor16nOC+Lh2/fwA3rFul61CICKDyKiEiM5xrauXf7flp6h7n90mX8zeY1FOboetQiMkHhUURE6Ogf5f6nXuXJl1qpLs/nB39+ORev0PWoRWQqhUcRkRQWiRy/HvVrjIQifO7aWj65aZWuRy0iM1J4FBFJUU3tA3xx+z5+/3o3l670rkddVabrUYvIySk8ioikgB31LTz0TAOtvcMsLszmgqWFPHugg5xAOg/+yQV8oG6pNsSIiC8KjyIi89yO+hbu2baP4VAYgNa+EVr7RtiwrIhHPlpHaX5WgisUkblEp7yKiMxjzjm+8pPXxoNjrLZjowqOIjJrGnkUEZln+oZD/Kapk+cbO9jV2EF7/+i07Vp7h+NcmYjMBwqPIiJz0Ruu3wAAEfNJREFUXDjieLm5l12Nnew62MGLb/USjjgKsjK4orqUoWAXvcOhKZ+3pCgnAdWKyFyn8CgiMge1HRsZH1n8VVMnvUMhzOCCykI+fWUVG2vLuPCcIjLT06aseQTIyUxn63WrE/gTiMhcpfAoIjIHjITC7DnSw/ON7exq7KShrR+A8oIsrllbwcbaMt5dXUpxXmDK5960vhJgfLf1kqIctl63evxxEZHZUHgUEUlCzjkOdQyyq7GDXQc72H24i5FQhEB6GhevXMgtG9awsbaMNYsKfB2xc9P6SoVFETkjFB5FRJLEsZHYjS6dtEQ3tKwqzeO2i5exqbaMS1cVkxvQS7eIJI5egUREEiQccexr6fNGFxs7qI9udMnPyuCK6hI+fVUVG2vKOKc4N9GlioiMU3gUEYmjtmMj0anoTn51sIOe6EaXdZWFfGqTt9Fl/TJvo4uISDJSeBQROYtGx8K88HoPuw56o4sHjnobXcoKsrhqTTmbohtdSnRYt4jMEQqPIiJnkHOOw52D41PRuw93MxwKk5luXLyimLuvX8PGmjLWLva30UVEJNkoPIqIvEPeRpcudh3s4PmGjvGNLitL8/hg3VI21pZx2aoS8rL0kisic59eyUREZrCjvmXasxEjsRtdDnaw982JjS6XV5XwqSur2FSrjS4iMj+Zcy7RNZxxdXV1bs+ePYkuQ0TmsOmuypKZbqxbUsiR7iG6B4OAt9FlY20pG2vK2LB8oTa6iMismdkfnHN1ia7DL408iohM46FnGk4IjgChsOPF5l5uurDSu6JLTSml2ugiIilG4VFEJEbXwChPvtQ6vm5xMufg6x+6MM5ViYgkD4VHEUl5o2Nhnn2tnR/ubeEXDe2MRRwZacZYZOqyniVFOQmoUEQkeSg8ikhKcs6x980efri3hadeauXYyBjlBVnc+e6V3LyhkgNv909Z85iTmc7W61YnsGoRkcRTeBSRlPJm1xDb6pvZXt/CG11D5GSms/n8Rdy8vpIrqktJT/POXlyzaAHAtLutRURSmcKjiMx7fcMhfvzy22yvb+aFIz2YweWrSvjs1TVsPn8R+TOcv3jT+kqFRRGRSRQeRWReCoUjPN/Qwfb6Fn72WhvBsQjV5fl8YfNqbrqwUmsXRUROk8KjiMwbznmHd2/b28KTL7XSNRikOC/A7Zcs45YNlayrLNQlAUVE3iGFRxGZ81p7h9nxYgvb9rbQ1D5AID2Na8+t4Ob1lWxaXaaDu0VEziCFRxGZkwZGx3h6/1G27W3mt4e7cA7qli/kKzev433rFlOYm5noEkVE5iWFRxGZM8IRx6+bOtle38LT+48yHAqzrDiXv3xPDTevr2R5SV6iSxQRmfcUHkUk6R04eozte1vY8WILbcdGWZCdwc0bKrllfSUXLV+odYwiInGk8CgiSam9f4SdL7aybW8Lr759jIw048rVZXzp/Uu5ek052ZnpiS5RRCQlKTyKSNIYCYX5v1fb2La3mV8e7CQccVywtJD73n8u73/XEkrysxJdoohIylN4FJGEikQcvz/Szba9zfx031H6R8dYXJjNJzeu4pYNlVSXFyS6RBERiaHwKCIJcbhjgO313vE6Lb3D5AXSuX7dYm5ZX8llq0pIS9M6RhGRZKTweBp21Lfoercip6FnMMhTL7fyw70tvPhWL2kGV1SXsvW61bz3vApyA3pJEhFJdnqlnqUd9S3cs20fw6EwAC29w9yzbR+AAqQIU/+4uuuaGvKzM9m2t5nnGtoJhR2rKwr44g1r2HJhJRULshNdsoiIzILC4yw99EzDeHA8bjgU5ks7X2FRYTZVZfmU5gd0dIikpOn+uPrrJ14GoDQ/i49dvoKbN1Ry7uIFeo6IiMxRCo+z1No7PO3jfcMhbntkNwCFOZlUleVRXZ5PdXk+VWXe+6ULc0nXOi6ZZ0LhCEc6B2lsG+DvfrR/yh9XACV5AXbfczUZukygiMicp/A4S0uKcmiZJkBWLMjiwVvfxaH2AZo6BjjUPsCzB9p5fE/zeJtARhqrSvOoigmUVWV5VJXl68w6SXrhiOPN7iEa2/ppPNpPY/sAjUf7Odw5QCjsTvq53YNBBUcRkXlC4XGWtl63+oRpOYCczHTuuX4tm2rL2FRbdkL73qEghzoGaGof4FDHIE3tA+xv6eMn+97GRX/fmkFlUc4Jo5THbxfnBeL544ngnKOld9gLiW1eQGxo66epfYDRsch4u6ULc6itKOCqNeXUVuRTW1HAJx7bQ2vfyJSvuaQoJ54/goiInEUKj7N0fFOM393WRbkBLlpezEXLi094fCQU5vXOwSnB8reHuk74BV2cFxifAq8qy6eqPJ/qsnwqi3J0lIm8I8452vtHaTjaHw2KXlg82NbPYHDij6NFC7KpqcjnTy9bTm1FAbWLCqgpzycva+rLxxc2r5n2j6ut162Oy88kIiJnnzl38ummuaiurs7t2bMn0WWclkjEG/U5PvXtBUvvfc9QaLxddmYaq0onwmR1eT5V5XmsKMmbcQpcRwylrq6BURra+jnYNhB930/D0X6OjYyNtynND1BTXsDqRQXUVOSzuqKAmooCCnMyZ/W99P9MRGR2zOwPzrm6RNfhl8LjHNI9GKRpUqA81DFAc8/EGsw0g3OKc6mOGaWsKs+n4egxvvzUa1NGhL56yzr9Yp9H+oZDXjA8vi6xbYDGtn66BoPjbQpzMsenmSfe8nXpPxGRBJlr4VHT1nNIcV6AS1YWc8nKE6fAh4NhDndGw2TMFPgvD3YSDEdm+GreEUP37XyF7Mw0FuYGWJgXYGFugKLcTDK1uSGpDY6OcTC6YaUxGhYPtg1w9NjEesO8QDo1FQVcs7bCG0lc5AXF8oIsHZMjIiKnTSOP81g44nire4hDHQPc+b3Z/XssyM4YD5PF0fcLczNZmHfi/eI8L3QW5WRqN+1pOtk070goTFP7wMTmlejaxNjR5uzMNKrLJ0YSvelmb12sQqKISPKbayOPCo8p4ooHnp32iKFFC7J49I6L6R0K0T0YpGcoSPdgcMb7053hd9yC7IzxMOmFywDFeZmT7nuPFeW+s8A519fVhSOO4FiE7fXN3P/kq4zEbJLKSDPWLCpgMBjmja5BItGnaGa6UVWWPz7NfDwsnlOs80NFROayuRYeNW2dImY6Yuju69dy3pJC319nJBQeD5Q9gyG6h4L0jt8P0j0UoncoSNuxEQ68fYzuoSAjoZmnzgtzvNHLotxMisenzqMjnDFT6cV5mdEp9QBPvtQ660tERiKOYDjCaCjCaDhMcCzivYUjE7fHIoxG3058PHzC/enbRCa1CU9tE3N7LDLzH21jEceBo/2897wKbnzXkuh0cz7LS/K0nEBERBJOI48pJFGjdcPBmMA5FKRnKOQFzWnu9w4F6RoMnnBcUazjs7DT/bfNSDOWleTOOqzNhhkE0tMIZKSRlZE2ftu7n+7djnkskJFGVmz742/pXtuvPX1g+u8DvP7A+85IzSIiktw08ihJ66b1lQmZ2s0JpJMTyJnVQdHDwTDdQ95oZk/MyGbPUIhv/vzgtJ8zFnGsXbxgPKzFBrnxYDcp0J3YJjYITgS82Mcy0uyMriP8r91vTLucQIdqi4hIsopbeDSzzcA3gXTgW865ByZ9PAt4DLgI6AI+5Jw7YmaZwLeADdF6H3POfTVedUti5ATSqQzkUDlNiHriD83TBq7Kohwevn1DPMo7Y2ZaTqBDtUVEJFnFZQGVmaUDDwPXA+cCHzazcyc1uxPocc5VA98AvhZ9/ANAlnNuHV6w/KSZrYhH3ZKctl63mpxJB6HP1cB10/pKvnrLOm9nNF4A1tmbIiKSzOI18ngJ0OScOwxgZt8HtgCvxrTZAtwXvf0E8M/mzQ86IM/MMoAcIAgci1PdkoRme4nIZJeo5QQiIiKnI17hsRJ4K+Z+M3DpTG2cc2Nm1geU4AXJLcDbQC5wl3Ou+6xXLElNgUtERCQx4nXux3Q7DCZvf52pzSVAGFgCrAQ+b2arpnwDs0+Y2R4z29PR0fFO6xURERGRacQrPDYD58TcXwq0ztQmOkVdCHQDtwNPO+dCzrl24NfAlO3szrlHnHN1zrm6srKys/AjiIiIiEi8wuMLQI2ZrTSzAHAbsHNSm53Ax6K3bwWedd4hlG8CV5snD7gMmP5wPBERERE5q+ISHp1zY8BngGeA14DHnXOvmNn9ZnZjtNmjQImZNQGfA+6OPv4wkA/sxwuh33HOvRyPukVERETkRLrCjIiIiEgCzbUrzOhCuSIiIiLim8KjiIiIiPim8CgiIiIivik8ioiIiIhvCo8iIiIi4pvCo4iIiIj4pvAoIiIiIr4pPIqIiIiIbwqPIiIiIuKbwqOIiIiI+DYvL09oZh3AG2f4y5YCnWf4a8o7p35JXuqb5KR+SV7qm+QUj35Z7pwrO8vf44yZl+HxbDCzPXPpupOpQv2SvNQ3yUn9krzUN8lJ/TKVpq1FRERExDeFRxERERHxTeHRv0cSXYBMS/2SvNQ3yUn9krzUN8lJ/TKJ1jyKiIiIiG8aeRQRERER3xQeY5jZZjNrMLMmM7t7mo9nmdn/Rj/+OzNbEf8qU5OPvvmcmb1qZi+b2c/NbHki6kw1p+qXmHa3mpkzM+1YjBM/fWNmH4w+b14xs/+Od42pyMdr2TIze87M6qOvZzckos5UY2bfNrN2M9s/w8fNzP4p2m8vm9mGeNeYTBQeo8wsHXgYuB44F/iwmZ07qdmdQI9zrhr4BvC1+FaZmnz2TT1Q55y7AHgCeDC+VaYen/2CmRUAfwH8Lr4Vpi4/fWNmNcA9wBXOufOAv4p7oSnG53PmXuBx59x64DbgX+JbZcr6LrD5JB+/HqiJvn0C+Nc41JS0FB4nXAI0OecOO+eCwPeBLZPabAG+F739BPAeM7M41piqTtk3zrnnnHND0bu7gaVxrjEV+XnOAHwZL8yPxLO4FOenbz4OPOyc6wFwzrXHucZU5KdfHLAgersQaI1jfSnLObcL6D5Jky3AY86zGygys8XxqS75KDxOqATeirnfHH1s2jbOuTGgDyiJS3WpzU/fxLoT+OlZrUjAR7+Y2XrgHOfcU/EsTHw9Z2qBWjP7tZntNrOTjbrImeGnX+4DPmJmzcBPgM/GpzQ5hdn+HprXMhJdQBKZbgRx8lZ0P23kzPP9725mHwHqgE1ntSKBU/SLmaXhLe+4I14FyTg/z5kMvCm4K/FG6n9pZuc753rPcm2pzE+/fBj4rnPuH8zscuA/o/0SOfvlyUno938MjTxOaAbOibm/lKnTBeNtzCwDb0rhZMPccmb46RvM7Brgb4EbnXOjcaotlZ2qXwqA84FfmNkR4DJgpzbNxIXf17MfOedCzrnXgQa8MClnj59+uRN4HMA591sgG+/aypJYvn4PpQqFxwkvADVmttLMAngLlXdOarMT+Fj09q3As04HZcbDKfsmOj3673jBUWu34uOk/eKc63POlTrnVjjnVuCtRb3RObcnMeWmFD+vZzuAqwDMrBRvGvtwXKtMPX765U3gPQBmthYvPHbEtUqZzk7go9Fd15cBfc65txNdVKJo2jrKOTdmZp8BngHSgW87514xs/uBPc65ncCjeFMITXgjjrclruLU4bNvHgLygR9E9zC96Zy7MWFFpwCf/SIJ4LNvngHea2avAmFgq3OuK3FVz38+++XzwH+Y2V1406J3aJDi7DOz/8FbwlEaXW/6JSATwDn3b3jrT28AmoAh4M8SU2ly0BVmRERERMQ3TVuLiIiIiG8KjyIiIiLim8KjiIiIiPim8CgiIiIivik8ioiIiIhvCo8iIiIi4pvCo4iIiIj4pvAoIuKDma0zszfM7FOJrkVEJJEUHkVEfHDO7cO7qtRHE12LiEgiKTyKiPjXDpyX6CJERBJJ4VFExL8HgCwzW57oQkREEkXhUUTEBzPbDOQBP0ajjyKSwhQeRUROwcyygQeBTwP7gPMTW5GISOIoPIqInNq9wGPOuSMoPIpIilN4FBE5CTNbDVwL/GP0IYVHEUlp5pxLdA0iIiIiMkdo5FFEREREfFN4FBERERHfFB5FRERExDeFRxERERHxTeFRRERERHxTeBQRERER3xQeRURERMQ3hUcRERER8e3/AX6cgfAKGjG5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# - Choose \"best alpha\" (minimal RMSE)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "plt.title('RMSE (at best alpha) for TD Methods vs. Supervised WH Procedure')\n",
    "\n",
    "best_alphas = np.min(np.array(experiment2b_rmses), axis=1)\n",
    "ax.plot(lambdas, best_alphas, marker='o')\n",
    "ax.annotate('Widrow-Hoff', (lambdas[-1], best_alphas[-1]))\n",
    "\n",
    "fig.gca().set_xlabel(r'$\\lambda$')\n",
    "fig.gca().set_ylabel(r'$RMSE$ (at best $\\alpha$)')\n",
    "\n",
    "fig.savefig('img/Project1-Fig5-REPRODUCED.png', dpi=fig.dpi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
